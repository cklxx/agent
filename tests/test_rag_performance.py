#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAGåŠŸèƒ½æ€§èƒ½æµ‹è¯•
"""

import tempfile
import time
import threading
import gc
import os
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from unittest.mock import Mock


class TestRAGPerformance:
    """æµ‹è¯•RAGåŠŸèƒ½çš„æ€§èƒ½æŒ‡æ ‡"""

    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        self.temp_dir = tempfile.mkdtemp()
        self.workspace = Path(self.temp_dir) / "perf_workspace"
        self.workspace.mkdir()

        # åˆ›å»ºæ€§èƒ½æµ‹è¯•æ–‡ä»¶ç»“æ„
        self.create_performance_test_files()

    def teardown_method(self):
        """æµ‹è¯•åæ¸…ç†"""
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶

    def create_performance_test_files(self):
        """åˆ›å»ºæ€§èƒ½æµ‹è¯•ç”¨çš„æ–‡ä»¶ç»“æ„"""
        # åˆ›å»ºå¤šå±‚ç›®å½•ç»“æ„
        for level1 in range(3):
            level1_dir = self.workspace / f"level1_{level1}"
            level1_dir.mkdir()

            for level2 in range(5):
                level2_dir = level1_dir / f"level2_{level2}"
                level2_dir.mkdir()

                # åœ¨æ¯ä¸ªç›®å½•åˆ›å»ºå¤šä¸ªPythonæ–‡ä»¶
                for file_idx in range(10):
                    file_path = level2_dir / f"module_{file_idx}.py"
                    file_content = f"""
# Module {level1}_{level2}_{file_idx}
import os
import sys

class Module{level1}{level2}{file_idx}:
    def __init__(self):
        self.name = "module_{level1}_{level2}_{file_idx}"
    
    def process_data(self, input_data):
        result = {{}}
        for item in input_data:
            result[item] = len(item) + {file_idx}
        return result

def main():
    module = Module{level1}{level2}{file_idx}()
    print(f"Module: {{module.name}}")

if __name__ == "__main__":
    main()
"""
                    file_path.write_text(file_content)

        print(f"åˆ›å»ºäº† {3 * 5 * 10} ä¸ªæµ‹è¯•æ–‡ä»¶ç”¨äºæ€§èƒ½æµ‹è¯•")

    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        try:
            import psutil

            process = psutil.Process(os.getpid())
            return process.memory_info().rss / 1024 / 1024
        except ImportError:
            return 0.0  # å¦‚æœæ²¡æœ‰psutilï¼Œè¿”å›0

    def test_path_validation_performance(self):
        """æµ‹è¯•è·¯å¾„éªŒè¯æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•è·¯å¾„éªŒè¯æ€§èƒ½")

        def is_path_in_workspace(file_path: str, workspace_path: Path) -> bool:
            try:
                resolved_path = Path(file_path).resolve()
                return (
                    resolved_path == workspace_path
                    or workspace_path in resolved_path.parents
                )
            except Exception:
                return False

        workspace_resolved = self.workspace.resolve()

        # å‡†å¤‡æµ‹è¯•è·¯å¾„
        test_paths = []

        # å†…éƒ¨è·¯å¾„
        for level1 in range(3):
            for level2 in range(5):
                for file_idx in range(10):
                    path = str(
                        self.workspace
                        / f"level1_{level1}"
                        / f"level2_{level2}"
                        / f"module_{file_idx}.py"
                    )
                    test_paths.append((path, True))

        # å¤–éƒ¨è·¯å¾„
        for i in range(50):
            path = str(Path(self.temp_dir) / f"outside_{i}.py")
            test_paths.append((path, False))

        print(f"å‡†å¤‡æµ‹è¯• {len(test_paths)} ä¸ªè·¯å¾„")

        # æ€§èƒ½æµ‹è¯•
        start_memory = self.get_memory_usage()
        start_time = time.time()

        correct_results = 0
        for path, expected in test_paths:
            result = is_path_in_workspace(path, workspace_resolved)
            if result == expected:
                correct_results += 1

        end_time = time.time()
        end_memory = self.get_memory_usage()

        elapsed_time = end_time - start_time
        memory_diff = end_memory - start_memory
        paths_per_second = len(test_paths) / elapsed_time if elapsed_time > 0 else 0

        print(f"âœ… è·¯å¾„éªŒè¯æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   æ€»è·¯å¾„æ•°: {len(test_paths)}")
        print(f"   æ­£ç¡®ç‡: {(correct_results/len(test_paths))*100:.1f}%")
        print(f"   æ€»è€—æ—¶: {elapsed_time:.3f}ç§’")
        print(f"   å¤„ç†é€Ÿåº¦: {paths_per_second:.0f} è·¯å¾„/ç§’")
        print(f"   å†…å­˜å˜åŒ–: {memory_diff:.1f}MB")

        # æ€§èƒ½æ–­è¨€
        assert correct_results == len(test_paths), "æ‰€æœ‰è·¯å¾„éªŒè¯åº”è¯¥æ­£ç¡®"
        assert (
            paths_per_second > 100
        ), f"å¤„ç†é€Ÿåº¦åº”è¯¥ > 100 è·¯å¾„/ç§’ï¼Œå®é™…: {paths_per_second:.0f}"

    def test_result_filtering_performance(self):
        """æµ‹è¯•ç»“æœè¿‡æ»¤æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•ç»“æœè¿‡æ»¤æ€§èƒ½")

        def filter_rag_results_by_workspace(
            results: list, workspace_path: Path
        ) -> list:
            def is_path_in_workspace(file_path: str) -> bool:
                try:
                    resolved_path = Path(file_path).resolve()
                    return (
                        resolved_path == workspace_path
                        or workspace_path in resolved_path.parents
                    )
                except Exception:
                    return False

            filtered_results = []
            for result in results:
                file_path = result.get("file_path", "")
                if is_path_in_workspace(file_path):
                    filtered_results.append(result)
            return filtered_results

        workspace_resolved = self.workspace.resolve()

        # åˆ›å»ºæ¨¡æ‹Ÿç»“æœ
        large_results = []

        # å†…éƒ¨æ–‡ä»¶ç»“æœ
        for level1 in range(3):
            for level2 in range(5):
                for file_idx in range(10):
                    file_path = str(
                        self.workspace
                        / f"level1_{level1}"
                        / f"level2_{level2}"
                        / f"module_{file_idx}.py"
                    )
                    large_results.append(
                        {
                            "file_path": file_path,
                            "title": f"module_{file_idx}.py",
                            "content": f"class Module{level1}{level2}{file_idx}: pass",
                            "similarity": 0.8 + (file_idx % 10) / 50,
                            "source": "rag_enhanced",
                        }
                    )

        # å¤–éƒ¨æ–‡ä»¶ç»“æœ
        for i in range(100):
            file_path = str(Path(self.temp_dir) / f"outside_{i}.py")
            large_results.append(
                {
                    "file_path": file_path,
                    "title": f"outside_{i}.py",
                    "content": f"def outside_function_{i}(): pass",
                    "similarity": 0.5 + (i % 20) / 40,
                    "source": "rag_basic",
                }
            )

        print(f"å‡†å¤‡è¿‡æ»¤ {len(large_results)} ä¸ªç»“æœ")

        # æ€§èƒ½æµ‹è¯•
        start_memory = self.get_memory_usage()
        start_time = time.time()

        filtered_results = filter_rag_results_by_workspace(
            large_results, workspace_resolved
        )

        end_time = time.time()
        end_memory = self.get_memory_usage()

        elapsed_time = end_time - start_time
        memory_diff = end_memory - start_memory
        results_per_second = (
            len(large_results) / elapsed_time if elapsed_time > 0 else 0
        )

        print(f"âœ… ç»“æœè¿‡æ»¤æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   åŸå§‹ç»“æœæ•°: {len(large_results)}")
        print(f"   è¿‡æ»¤åç»“æœæ•°: {len(filtered_results)}")
        print(
            f"   è¿‡æ»¤ç‡: {((len(large_results)-len(filtered_results))/len(large_results))*100:.1f}%"
        )
        print(f"   æ€»è€—æ—¶: {elapsed_time:.3f}ç§’")
        print(f"   å¤„ç†é€Ÿåº¦: {results_per_second:.0f} ç»“æœ/ç§’")
        print(f"   å†…å­˜å˜åŒ–: {memory_diff:.1f}MB")

        # éªŒè¯è¿‡æ»¤æ­£ç¡®æ€§
        expected_internal = 3 * 5 * 10  # 150ä¸ªå†…éƒ¨æ–‡ä»¶
        assert (
            len(filtered_results) == expected_internal
        ), f"åº”è¯¥ä¿ç•™{expected_internal}ä¸ªå†…éƒ¨ç»“æœ"
        assert (
            results_per_second > 50
        ), f"å¤„ç†é€Ÿåº¦åº”è¯¥ > 50 ç»“æœ/ç§’ï¼Œå®é™…: {results_per_second:.0f}"

    def test_concurrent_search_performance(self):
        """æµ‹è¯•å¹¶å‘æœç´¢æ€§èƒ½"""
        print("ğŸ§ª æµ‹è¯•å¹¶å‘æœç´¢æ€§èƒ½")

        def mock_rag_search(query: str, workspace: str, search_id: int) -> dict:
            """æ¨¡æ‹ŸRAGæœç´¢æ“ä½œ"""
            # æ¨¡æ‹Ÿæœç´¢å»¶è¿Ÿ
            time.sleep(0.05)  # å‡å°‘å»¶è¿Ÿä»¥åŠ å¿«æµ‹è¯•

            # æ¨¡æ‹Ÿæœç´¢ç»“æœ
            return {
                "search_id": search_id,
                "query": query,
                "workspace": workspace,
                "results": [
                    {
                        "file_path": f"result_{search_id}_{i}.py",
                        "content": f"def result_function_{search_id}_{i}(): pass",
                        "similarity": 0.8 - i * 0.1,
                    }
                    for i in range(3)
                ],
                "search_time": time.time(),
            }

        # å‡†å¤‡æœç´¢æŸ¥è¯¢
        queries = [f"search_query_{i}" for i in range(10)]

        # ä¸²è¡Œæœç´¢æµ‹è¯•
        start_time = time.time()
        serial_results = []
        for i, query in enumerate(queries):
            result = mock_rag_search(query, str(self.workspace), i)
            serial_results.append(result)
        serial_time = time.time() - start_time

        # å¹¶è¡Œæœç´¢æµ‹è¯•
        start_time = time.time()
        parallel_results = []

        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [
                executor.submit(mock_rag_search, query, str(self.workspace), i)
                for i, query in enumerate(queries)
            ]

            for future in as_completed(futures):
                result = future.result()
                parallel_results.append(result)

        parallel_time = time.time() - start_time

        # æ€§èƒ½åˆ†æ
        speedup = serial_time / parallel_time if parallel_time > 0 else 1
        efficiency = speedup / 3  # 3ä¸ªå·¥ä½œçº¿ç¨‹

        print(f"âœ… å¹¶å‘æœç´¢æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   æœç´¢æŸ¥è¯¢æ•°: {len(queries)}")
        print(f"   ä¸²è¡Œè€—æ—¶: {serial_time:.2f}ç§’")
        print(f"   å¹¶è¡Œè€—æ—¶: {parallel_time:.2f}ç§’")
        print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"   å¹¶è¡Œæ•ˆç‡: {efficiency:.2f}")
        print(f"   ä¸²è¡Œç»“æœæ•°: {len(serial_results)}")
        print(f"   å¹¶è¡Œç»“æœæ•°: {len(parallel_results)}")

        # æ€§èƒ½æ–­è¨€
        assert (
            len(serial_results) == len(parallel_results) == len(queries)
        ), "ç»“æœæ•°é‡åº”è¯¥ç›¸åŒ"
        assert speedup > 1.5, f"å¹¶è¡ŒåŠ é€Ÿæ¯”åº”è¯¥ > 1.5ï¼Œå®é™…: {speedup:.2f}"

    def test_memory_efficiency(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æ•ˆç‡"""
        print("ğŸ§ª æµ‹è¯•å†…å­˜ä½¿ç”¨æ•ˆç‡")

        def memory_efficient_processing(data_size: int, batch_size: int = 50):
            """å†…å­˜é«˜æ•ˆçš„æ‰¹å¤„ç†"""
            results = []

            for i in range(0, data_size, batch_size):
                # å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡
                batch = []
                for j in range(min(batch_size, data_size - i)):
                    item = {
                        "id": i + j,
                        "data": f"item_{i+j}_data_" * 5,  # é€‚ä¸­çš„æ•°æ®é¡¹
                        "processed": True,
                    }
                    batch.append(item)

                # æ¨¡æ‹Ÿå¤„ç†
                processed_batch = [
                    {"id": item["id"], "summary": f"summary_{item['id']}"}
                    for item in batch
                ]
                results.extend(processed_batch)

                # æ¸…ç†æ‰¹æ¬¡æ•°æ®
                del batch

                # å®šæœŸåƒåœ¾å›æ”¶
                if i % (batch_size * 5) == 0:
                    gc.collect()

            return results

        # æµ‹è¯•ä¸åŒæ•°æ®å¤§å°çš„å†…å­˜æ•ˆç‡
        test_sizes = [100, 300, 500]

        for data_size in test_sizes:
            print(f"\næµ‹è¯•æ•°æ®å¤§å°: {data_size}")

            start_memory = self.get_memory_usage()
            start_time = time.time()

            results = memory_efficient_processing(data_size, batch_size=30)

            end_time = time.time()
            end_memory = self.get_memory_usage()

            elapsed_time = end_time - start_time
            memory_diff = end_memory - start_memory
            items_per_second = len(results) / elapsed_time if elapsed_time > 0 else 0
            memory_per_item = memory_diff / len(results) if len(results) > 0 else 0

            print(f"   å¤„ç†é¡¹ç›®æ•°: {len(results)}")
            print(f"   å¤„ç†æ—¶é—´: {elapsed_time:.3f}ç§’")
            print(f"   å¤„ç†é€Ÿåº¦: {items_per_second:.0f} é¡¹ç›®/ç§’")
            print(f"   å†…å­˜å˜åŒ–: {memory_diff:.1f}MB")
            print(f"   å•é¡¹å†…å­˜: {memory_per_item*1024:.2f}KB")

            # æ€§èƒ½æ–­è¨€
            assert len(results) == data_size, f"åº”è¯¥å¤„ç†{data_size}ä¸ªé¡¹ç›®"


def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("âš¡ å¼€å§‹RAGåŠŸèƒ½æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    test_instance = TestRAGPerformance()

    test_methods = [
        test_instance.test_path_validation_performance,
        test_instance.test_result_filtering_performance,
        test_instance.test_concurrent_search_performance,
        test_instance.test_memory_efficiency,
    ]

    passed = 0
    failed = 0

    for test_method in test_methods:
        try:
            test_instance.setup_method()
            test_method()
            test_instance.teardown_method()
            passed += 1
            print(f"âœ… {test_method.__name__} é€šè¿‡")
        except Exception as e:
            failed += 1
            print(f"âŒ {test_method.__name__} å¤±è´¥: {e}")
        print("-" * 40)

    print(f"\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
    print(f"æ€»æµ‹è¯•æ•°: {len(test_methods)}")
    print(f"é€šè¿‡: {passed} âœ…")
    print(f"å¤±è´¥: {failed} âŒ")
    print(f"æˆåŠŸç‡: {(passed/len(test_methods))*100:.1f}%")

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æ€§èƒ½æµ‹è¯•é€šè¿‡!")
        print("RAGåŠŸèƒ½åœ¨æ€§èƒ½æ–¹é¢è¡¨ç°è‰¯å¥½")

    return failed == 0


if __name__ == "__main__":
    success = run_performance_tests()
    exit(0 if success else 1)
