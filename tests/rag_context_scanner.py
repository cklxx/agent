#!/usr/bin/env python3
"""
RAG Context Scanner - æ‰«æå’Œåˆ†æžå½“å‰æ–‡ä»¶å¤¹ä¸‹çš„RAGç›¸å…³å†…å®¹
ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºŽæ–‡ä»¶å†…å®¹åˆ†æžï¼Œé¿å…å¤æ‚çš„æ¨¡å—å¯¼å…¥
"""

import os
import re
import ast
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from collections import defaultdict


class RAGContextScanner:
    """RAG Contextå†…å®¹æ‰«æå™¨"""

    def __init__(self, target_dir: str = "."):
        """
        åˆå§‹åŒ–RAG Contextæ‰«æå™¨

        Args:
            target_dir: ç›®æ ‡æ‰«æç›®å½•
        """
        self.target_dir = Path(target_dir).resolve()
        self.scan_results = {}

        print(f"ðŸ” RAG Contextæ‰«æå™¨å¯åŠ¨")
        print(f"ðŸ“ æ‰«æç›®å½•: {self.target_dir}")

    def scan_rag_files(self) -> Dict[str, Any]:
        """æ‰«æåŒ…å«RAGç›¸å…³å†…å®¹çš„æ–‡ä»¶"""
        rag_keywords = [
            "rag",
            "RAG",
            "context",
            "Context",
            "retriever",
            "enhanced",
            "semantic",
            "embedding",
            "vector",
            "search",
            "query",
            "ContextType",
            "RAG_CODE",
            "RAG_SEMANTIC",
            "rag_context",
        ]

        scan_results = {
            "files_scanned": 0,
            "rag_files": [],
            "file_analysis": {},
            "summary": {
                "total_rag_functions": 0,
                "total_rag_classes": 0,
                "total_context_types": 0,
                "total_test_methods": 0,
                "file_types": defaultdict(int),
            },
        }

        for root, dirs, files in os.walk(self.target_dir):
            # è·³è¿‡éšè—ç›®å½•å’Œç¼“å­˜ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith((".", "__pycache__"))]

            for file in files:
                if file.endswith((".py", ".md", ".txt", ".json", ".yaml", ".yml")):
                    scan_results["files_scanned"] += 1
                    file_path = Path(root) / file

                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            content = f.read()

                        # æ£€æŸ¥æ˜¯å¦åŒ…å«RAGç›¸å…³å…³é”®è¯
                        rag_keyword_matches = sum(
                            1 for keyword in rag_keywords if keyword in content
                        )

                        if rag_keyword_matches > 0:
                            scan_results["rag_files"].append(str(file_path))
                            analysis = self.analyze_file_content(file_path, content)
                            scan_results["file_analysis"][str(file_path)] = analysis

                            # æ›´æ–°æ±‡æ€»ç»Ÿè®¡
                            summary = scan_results["summary"]
                            summary["total_rag_functions"] += len(
                                analysis.get("rag_functions", [])
                            )
                            summary["total_rag_classes"] += len(
                                analysis.get("rag_classes", [])
                            )
                            summary["total_context_types"] += len(
                                analysis.get("rag_context_types", [])
                            )
                            summary["total_test_methods"] += len(
                                analysis.get("test_methods", [])
                            )
                            summary["file_types"][
                                analysis.get("file_type", "unknown")
                            ] += 1

                    except Exception as e:
                        print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        self.scan_results = scan_results
        return scan_results

    def analyze_file_content(self, file_path: Path, content: str) -> Dict[str, Any]:
        """åˆ†æžæ–‡ä»¶å†…å®¹ä¸­çš„RAGç›¸å…³ä¿¡æ¯"""
        analysis = {
            "file_path": str(file_path),
            "file_type": file_path.suffix,
            "file_size": len(content),
            "line_count": len(content.split("\n")),
            "rag_context_types": [],
            "rag_functions": [],
            "rag_classes": [],
            "context_instances": [],
            "test_methods": [],
            "import_statements": [],
            "rag_keywords": [],
            "has_rag_manager": False,
            "has_context_manager": False,
        }

        # Pythonæ–‡ä»¶ç‰¹æ®Šå¤„ç†
        if file_path.suffix == ".py":
            analysis.update(self.analyze_python_file(content))

        # é€šç”¨æ–‡æœ¬åˆ†æž
        analysis.update(self.analyze_text_content(content))

        return analysis

    def analyze_python_file(self, content: str) -> Dict[str, Any]:
        """åˆ†æžPythonæ–‡ä»¶çš„ASTç»“æž„"""
        analysis = {
            "rag_functions": [],
            "rag_classes": [],
            "context_instances": [],
            "imports": [],
        }

        try:
            tree = ast.parse(content)

            for node in ast.walk(tree):
                # åˆ†æžå¯¼å…¥è¯­å¥
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        if (
                            "rag" in alias.name.lower()
                            or "context" in alias.name.lower()
                        ):
                            analysis["imports"].append(
                                {
                                    "type": "import",
                                    "name": alias.name,
                                    "line": node.lineno,
                                }
                            )

                elif isinstance(node, ast.ImportFrom):
                    if node.module and (
                        "rag" in node.module.lower() or "context" in node.module.lower()
                    ):
                        for alias in node.names:
                            analysis["imports"].append(
                                {
                                    "type": "from_import",
                                    "module": node.module,
                                    "name": alias.name,
                                    "line": node.lineno,
                                }
                            )

                # åˆ†æžå‡½æ•°å®šä¹‰
                elif isinstance(node, ast.FunctionDef):
                    if any(
                        keyword in node.name.lower()
                        for keyword in ["rag", "context", "search", "retriev"]
                    ):
                        analysis["rag_functions"].append(
                            {
                                "name": node.name,
                                "line": node.lineno,
                                "args": [arg.arg for arg in node.args.args],
                                "is_async": isinstance(node, ast.AsyncFunctionDef),
                                "docstring": ast.get_docstring(node),
                                "is_test": node.name.startswith("test_"),
                            }
                        )

                # åˆ†æžç±»å®šä¹‰
                elif isinstance(node, ast.ClassDef):
                    if any(
                        keyword in node.name.lower()
                        for keyword in ["rag", "context", "retriev", "search"]
                    ):
                        analysis["rag_classes"].append(
                            {
                                "name": node.name,
                                "line": node.lineno,
                                "bases": [
                                    self._get_node_name(base) for base in node.bases
                                ],
                                "docstring": ast.get_docstring(node),
                                "methods": [
                                    method.name
                                    for method in node.body
                                    if isinstance(method, ast.FunctionDef)
                                ],
                            }
                        )

                # åˆ†æžå˜é‡èµ‹å€¼
                elif isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name) and any(
                            keyword in target.id.lower()
                            for keyword in ["context", "rag", "manager"]
                        ):
                            analysis["context_instances"].append(
                                {
                                    "name": target.id,
                                    "line": node.lineno,
                                    "type": (
                                        self._get_node_name(node.value)
                                        if hasattr(node.value, "id")
                                        else "unknown"
                                    ),
                                }
                            )

        except SyntaxError as e:
            analysis["parse_error"] = str(e)

        return analysis

    def analyze_text_content(self, content: str) -> Dict[str, Any]:
        """åˆ†æžæ–‡æœ¬å†…å®¹ä¸­çš„RAGç›¸å…³ä¿¡æ¯"""
        analysis = {
            "rag_context_types": [],
            "test_methods": [],
            "import_statements": [],
            "rag_keywords": [],
            "has_rag_manager": False,
            "has_context_manager": False,
        }

        lines = content.split("\n")

        # RAGç›¸å…³å…³é”®è¯
        rag_keywords = [
            "rag",
            "RAG",
            "context",
            "Context",
            "retriever",
            "enhanced",
            "semantic",
            "embedding",
            "vector",
            "search",
            "query",
        ]

        for i, line in enumerate(lines, 1):
            line_lower = line.lower()
            line_stripped = line.strip()

            # æ£€æµ‹Contextç±»åž‹å®šä¹‰
            if "contexttype" in line_lower and "rag" in line_lower:
                analysis["rag_context_types"].append(
                    {"line": i, "content": line_stripped[:100]}  # é™åˆ¶é•¿åº¦
                )

            # æ£€æµ‹å¯¼å…¥è¯­å¥
            if line_stripped.startswith(("import", "from")) and any(
                keyword in line_lower for keyword in ["rag", "context"]
            ):
                analysis["import_statements"].append(
                    {"line": i, "content": line_stripped}
                )

            # æ£€æµ‹æµ‹è¯•æ–¹æ³•
            if "def test" in line_lower and any(
                keyword in line_lower for keyword in ["rag", "context"]
            ):
                analysis["test_methods"].append(
                    {"line": i, "content": line_stripped[:80]}
                )

            # æ£€æµ‹ç‰¹å®šç±»
            if "ragcontextmanager" in line_lower or "rag_context_manager" in line_lower:
                analysis["has_rag_manager"] = True

            if "contextmanager" in line_lower and "rag" not in line_lower:
                analysis["has_context_manager"] = True

            # ç»Ÿè®¡å…³é”®è¯å‡ºçŽ°
            for keyword in rag_keywords:
                if keyword in line:
                    analysis["rag_keywords"].append(
                        {
                            "keyword": keyword,
                            "line": i,
                            "context": (
                                line_stripped[:50] + "..."
                                if len(line_stripped) > 50
                                else line_stripped
                            ),
                        }
                    )

        return analysis

    def _get_node_name(self, node) -> str:
        """èŽ·å–ASTèŠ‚ç‚¹çš„åç§°"""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            return f"{self._get_node_name(node.value)}.{node.attr}"
        elif isinstance(node, ast.Call):
            return self._get_node_name(node.func)
        else:
            return str(type(node).__name__)

    def generate_context_report(self) -> str:
        """ç”ŸæˆRAG Contextåˆ†æžæŠ¥å‘Š"""
        if not self.scan_results:
            return "âŒ æ²¡æœ‰æ‰«æç»“æžœï¼Œè¯·å…ˆè¿è¡Œscan_rag_files()"

        results = self.scan_results
        report = []

        # æŠ¥å‘Šå¤´éƒ¨
        report.append("# RAG Context æ‰«æåˆ†æžæŠ¥å‘Š")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æ‰«æç›®å½•**: {self.target_dir}")
        report.append("")

        # æ€»ä½“ç»Ÿè®¡
        report.append("## ðŸ“Š æ€»ä½“ç»Ÿè®¡")
        report.append(f"- æ€»æ‰«ææ–‡ä»¶æ•°: **{results['files_scanned']}**")
        report.append(f"- RAGç›¸å…³æ–‡ä»¶æ•°: **{len(results['rag_files'])}**")
        report.append(
            f"- RAGç›¸å…³å‡½æ•°æ€»æ•°: **{results['summary']['total_rag_functions']}**"
        )
        report.append(f"- RAGç›¸å…³ç±»æ€»æ•°: **{results['summary']['total_rag_classes']}**")
        report.append(
            f"- Contextç±»åž‹å®šä¹‰: **{results['summary']['total_context_types']}**"
        )
        report.append(f"- æµ‹è¯•æ–¹æ³•æ€»æ•°: **{results['summary']['total_test_methods']}**")
        report.append("")

        # æ–‡ä»¶ç±»åž‹åˆ†å¸ƒ
        if results["summary"]["file_types"]:
            report.append("## ðŸ“ æ–‡ä»¶ç±»åž‹åˆ†å¸ƒ")
            for file_type, count in results["summary"]["file_types"].items():
                report.append(f"- `{file_type}`: {count} ä¸ªæ–‡ä»¶")
            report.append("")

        # RAGæ–‡ä»¶åˆ—è¡¨
        report.append("## ðŸ“ RAGç›¸å…³æ–‡ä»¶åˆ—è¡¨")
        for file_path in results["rag_files"]:
            relative_path = Path(file_path).relative_to(self.target_dir)
            file_analysis = results["file_analysis"].get(file_path, {})

            # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            size_kb = file_analysis.get("file_size", 0) // 1024
            line_count = file_analysis.get("line_count", 0)

            report.append(f"### `{relative_path}`")
            report.append(f"- æ–‡ä»¶å¤§å°: {size_kb}KB, è¡Œæ•°: {line_count}")

            # RAGåŠŸèƒ½ç»Ÿè®¡
            rag_functions = len(file_analysis.get("rag_functions", []))
            rag_classes = len(file_analysis.get("rag_classes", []))
            test_methods = len(file_analysis.get("test_methods", []))

            if rag_functions > 0 or rag_classes > 0 or test_methods > 0:
                report.append(
                    f"- RAGåŠŸèƒ½: {rag_functions} ä¸ªå‡½æ•°, {rag_classes} ä¸ªç±», {test_methods} ä¸ªæµ‹è¯•"
                )

            # ç‰¹æ®Šæ ‡è®°
            if file_analysis.get("has_rag_manager"):
                report.append("- âœ… åŒ…å«RAG Manager")
            if file_analysis.get("has_context_manager"):
                report.append("- âœ… åŒ…å«Context Manager")

            report.append("")

        # è¯¦ç»†åŠŸèƒ½åˆ†æž
        report.append("## ðŸ” è¯¦ç»†åŠŸèƒ½åˆ†æž")

        for file_path, analysis in results["file_analysis"].items():
            relative_path = Path(file_path).relative_to(self.target_dir)

            if not (analysis.get("rag_functions") or analysis.get("rag_classes")):
                continue

            report.append(f"### {relative_path}")

            # RAGå‡½æ•°
            if analysis.get("rag_functions"):
                report.append("**RAGç›¸å…³å‡½æ•°:**")
                for func in analysis["rag_functions"][:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                    async_mark = "async " if func.get("is_async") else ""
                    test_mark = " [æµ‹è¯•]" if func.get("is_test") else ""
                    report.append(
                        f"- `{async_mark}{func['name']}()` (ç¬¬{func['line']}è¡Œ){test_mark}"
                    )

            # RAGç±»
            if analysis.get("rag_classes"):
                report.append("**RAGç›¸å…³ç±»:**")
                for cls in analysis["rag_classes"]:
                    method_count = len(cls.get("methods", []))
                    report.append(
                        f"- `{cls['name']}` (ç¬¬{cls['line']}è¡Œ, {method_count} ä¸ªæ–¹æ³•)"
                    )

            # Contextå®žä¾‹
            if analysis.get("context_instances"):
                report.append("**Contextå®žä¾‹:**")
                for instance in analysis["context_instances"][:5]:
                    report.append(f"- `{instance['name']}` (ç¬¬{instance['line']}è¡Œ)")

            report.append("")

        # Contextç±»åž‹åˆ†æž
        context_types_found = []
        for analysis in results["file_analysis"].values():
            context_types_found.extend(analysis.get("rag_context_types", []))

        if context_types_found:
            report.append("## ðŸ·ï¸ Contextç±»åž‹å®šä¹‰")
            unique_types = {}
            for ct in context_types_found:
                key = ct["content"][:50]
                if key not in unique_types:
                    unique_types[key] = ct

            for ct in list(unique_types.values())[:10]:
                report.append(f"- ç¬¬{ct['line']}è¡Œ: `{ct['content']}`")
            report.append("")

        # æ€»ç»“è¯„ä¼°
        report.append("## ðŸ“‹ æ€»ç»“è¯„ä¼°")

        total_files = len(results["rag_files"])
        has_managers = sum(
            1
            for analysis in results["file_analysis"].values()
            if analysis.get("has_rag_manager") or analysis.get("has_context_manager")
        )

        if total_files == 0:
            report.append("- çŠ¶æ€: âŒ æœªå‘çŽ°RAGç›¸å…³æ–‡ä»¶")
        elif total_files >= 10 and has_managers >= 2:
            report.append("- çŠ¶æ€: ðŸ† RAGé›†æˆéžå¸¸å®Œå–„")
        elif total_files >= 5 and has_managers >= 1:
            report.append("- çŠ¶æ€: ðŸ¥‡ RAGé›†æˆè‰¯å¥½")
        elif total_files >= 2:
            report.append("- çŠ¶æ€: ðŸ¥ˆ RAGé›†æˆåŸºç¡€å®Œå¤‡")
        else:
            report.append("- çŠ¶æ€: ðŸ¥‰ RAGé›†æˆåˆšèµ·æ­¥")

        report.append(
            f"- RAGæ–‡ä»¶è¦†ç›–çŽ‡: {(total_files / max(results['files_scanned'], 1) * 100):.1f}%"
        )

        return "\n".join(report)

    def save_report(self, filename: str = "rag_context_scan_report.md") -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report = self.generate_context_report()
        report_path = self.target_dir / filename

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        return str(report_path)

    def run_scan(self) -> str:
        """è¿è¡Œå®Œæ•´çš„æ‰«æå’ŒæŠ¥å‘Šç”Ÿæˆ"""
        print("ðŸš€ å¼€å§‹RAG Contextæ‰«æ...")

        # æ‰«ææ–‡ä»¶
        print("ðŸ“ æ‰«æRAGç›¸å…³æ–‡ä»¶...")
        results = self.scan_rag_files()
        print(f"   å‘çŽ° {len(results['rag_files'])} ä¸ªRAGç›¸å…³æ–‡ä»¶")

        # ç”ŸæˆæŠ¥å‘Š
        print("ðŸ“‹ ç”Ÿæˆæ‰«ææŠ¥å‘Š...")
        report = self.generate_context_report()

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.save_report()
        print(f"âœ… æ‰«æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

        return report


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ” RAG Context Scanner")
    print("=" * 40)

    # åˆ›å»ºæ‰«æå™¨å®žä¾‹
    scanner = RAGContextScanner(target_dir=".")

    # è¿è¡Œæ‰«æ
    report = scanner.run_scan()

    # æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ
    print("\nðŸ“‹ æ‰«ææŠ¥å‘Šé¢„è§ˆ:")
    print("=" * 40)

    lines = report.split("\n")
    preview_lines = lines[:30]  # æ˜¾ç¤ºå‰30è¡Œ

    for line in preview_lines:
        print(line)

    if len(lines) > 30:
        print(f"\n... è¿˜æœ‰ {len(lines) - 30} è¡Œå†…å®¹ï¼Œè¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šæ–‡ä»¶")

    return 0


if __name__ == "__main__":
    exit(main())
