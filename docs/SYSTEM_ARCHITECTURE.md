# System Architecture Document

## Introduction
This document provides an overview of the system architecture for the DeepTool project. It outlines the core components, their interactions, and the overall design philosophy.

## Core Philosophy
The DeepTool project is built upon a LangGraph-based multi-agent system. This architecture allows for modular, maintainable, and scalable development of complex AI-driven workflows.

## Entry Points
The system has the following primary entry points:
*   `main.py`: Handles Command Line Interface (CLI) interactions and invokes the main agent workflow via `src.workflow.run_agent_workflow_async`.
*   `server.py`: Hosts the FastAPI web server, providing a User Interface (UI) and API endpoints for interacting with the system.
*   `src.workflow.py`: Orchestrates the main LangGraph execution using `graph.astream`, managing the flow of tasks between different agents.

## Main Workflow (`src.workflow.py` and `src.graph.builder.py`)
The main workflow is defined and executed using LangGraph.
*   `build_graph()` (in `src.graph.builder.py`): This function is responsible for constructing the LangGraph, defining the nodes (agents) and edges (transitions) that represent the workflow logic.
*   Primary Nodes (defined in `src.graph.nodes.py`):
    *   `Coordinator`: Manages the overall task, breaking it down and delegating to other agents.
    *   `Planner`: Develops detailed plans for complex tasks.
    *   `BackgroundInvestigator`: Performs research and information gathering in the background.
    *   `HumanFeedback`: Allows for human intervention and guidance within the workflow.
    *   `ResearchTeam`: A sub-graph or group of agents focused on research tasks.
    *   `Researcher`: An individual agent responsible for specific research queries.
    *   `Coder`: An agent specialized in writing and modifying code.
    *   `Reporter`: Compiles results and generates final reports or outputs.

## Agent Implementations (`src.agents/`)
Specialized agents are implemented in the `src.agents/` directory.
*   `code_agent.py`:
    *   `CodeTaskPlanner`: An LLM-based planner (with fallback mechanisms) that devises multi-phase plans for coding tasks, typically including pre-analysis, implementation, and verification phases.
    *   `create_code_agent`: A factory function that creates a REACT (Reasoning and Acting) agent specifically tailored for code generation and modification tasks.
*   `rag_enhanced_code_agent.py`:
    *   `RAGEnhancedCodeTaskPlanner`: Extends the `CodeTaskPlanner` by incorporating Retrieval Augmented Generation (RAG). This allows the planner to use context from the existing codebase (retrieved via code indexing and searching) and project structure analysis to create more informed plans.
    *   `RAGEnhancedCodeAgent`: Wraps the REACT agent created by `create_code_agent` and injects the RAG-retrieved context into the prompts, enabling the agent to generate code that is more consistent with the existing project.
*   Workflows (`src.code_agent_workflow.py`, `src.rag_enhanced_code_agent_workflow.py`): These modules orchestrate the execution of the specialized code agents, managing their lifecycle and interactions.

## RAG Subsystem (`src.rag/`, `src.context/code_rag_adapter.py`)
The Retrieval Augmented Generation (RAG) subsystem provides context from the codebase to the agents.
*   `CodeIndexer` (`src.rag/code_indexer.py`): Scans the repository, parses code files (using Abstract Syntax Trees - ASTs for Python), chunks the code, and stores embeddings and metadata in an SQLite database for efficient retrieval.
*   `CodeRetriever` (`src.rag/code_retriever.py`): Queries the SQLite index to find code snippets relevant to a given query or task.
*   `CodeRAGAdapter` (`src.context/code_rag_adapter.py`): Integrates the RAG functionalities (indexing and retrieval) with the `ContextManager`, making codebase context available to agents.
*   For more detailed information on the RAG subsystem, refer to `docs/CODE_RAG_README.md`.

## Tool System (`src.tools/`)
The system includes a comprehensive tool system that agents can use to interact with the environment.
*   Overview: Tools include capabilities for web searching, file operations (read, write, list), executing terminal commands, running Python code in a REPL, crawling websites, interacting with maps, and text-to-speech (TTS).
*   MCP Integration: The tool system is integrated with the Multi-Context Prompting (MCP) framework, allowing for extensible and versioned toolsets.
*   A detailed list of available tools and their usage can be found in `docs/agent.md`.

## Configuration (`.env`, `conf.yaml`, `src.config/`)
System configuration is managed through several files:
*   `.env`: Stores environment-specific settings, such as API keys for external services and local development flags.
*   `conf.yaml`: Contains configuration for LLM models (e.g., model names, API endpoints), service URLs, and other semi-static parameters.
*   `src.config/configuration.py`: This module loads, validates, and provides application-wide access to the settings from `.env` and `conf.yaml`.

## LLM Integration (`src.llms/`)
The system integrates with Large Language Models (LLMs) through an abstraction layer.
*   Abstraction: Utilizes LiteLLM to provide a consistent interface for interacting with various LLM providers (e.g., OpenAI, Anthropic, local models).
*   Categorization: LLMs are categorized based on their intended use (e.g., 'reasoning' for complex tasks, 'basic' for simpler tasks), allowing the system to select appropriate models dynamically.

## Web Interface (`web/`)
A web-based user interface is provided for interacting with the DeepTool system.
*   Technology: Developed as a Next.js application.
*   Communication: Interacts with the Python backend through API calls defined in `server.py`.

## Data Flow Summary
A typical user request flows through the system as follows:
1.  User initiates a task via the CLI (`main.py`) or the Web UI (`server.py`).
2.  The request is routed to the `Coordinator` node in the main LangGraph workflow (`src.workflow.py`).
3.  The `Coordinator` may delegate to the `Planner` to break down the task into smaller steps.
4.  Depending on the task, specialized agents like `Coder` (for code tasks) or `ResearchTeam` (for information gathering) are invoked.
    *   These agents may use tools from `src.tools/` and context from the RAG subsystem (`src.rag/`).
5.  Human feedback may be solicited via the `HumanFeedback` node if required.
6.  Finally, the `Reporter` node compiles the results and generates the final output, which is returned to the user.

## Automated Codebase Analysis Summary
*   Total Files: 340
*   Main Languages: css (4 files), javascript (5 files), json (7 files), markdown (40 files), python (114 files)
*   Total Chunks (from RAG indexing): 9419
*   Common Code Patterns/Themes:
    *   {'file_path': 'src/rag_enhanced_code_agent_workflow.py', 'title': 'rag_enhanced_code_agent_workflow.py (python)', 'url': 'file://src/rag_enhanced_code_agent_workflow.py', 'chunks': [{'content': 'class RAGEnhancedCodeAgentWorkflow:\n    """RAG增强的代码代理工作流"""\n\n    def __init__(self, repo_path: str = "."):\n        """初始化RAG增强代码代理工作流"""\n        logger.info("初始化RAG增强代码代理工作流")\n\n        self.repo_path = repo_path\n\n        # 定义可用的工具\n        self.code_tools = [\n            # 命令行工具\n            execute_terminal_command,\n            get_current_directory,\n            list_directory_contents,\n            # 文件读取工具\n            read_file,\n            read_file_lines,\n            get_file_info,\n            # 文件写入工具\n            write_file,\n            append_to_file,\n            create_new_file,\n            generate_file_diff,\n        ]\n\n        logger.info(f"配置 {len(self.code_tools)} 个工具")\n\n        # 创建RAG增强的code agent\n        try:\n            self.agent = create_rag_enhanced_code_agent(\n                repo_path=repo_path, tools=self.code_tools\n            )\n            logger.info("RAG增强代码代理创建成功")\n        except Exception as e:\n            logger.error(f"创建RAG增强代码代理失败: {str(e)}")\n            raise\n\n    async def execute_task(\n        self, task_description: str, max_iterations: int = 5\n    ) -> Dict[str, Any]:\n        """\n        执行RAG增强的代码任务\n\n        Args:\n            task_description: 任务描述\n            max_iterations: 最大执行轮次\n\n        Returns:\n            任务执行结果\n        """\n        logger.info(f"🚀 开始执行RAG增强代码任务")\n        logger.info(\n            f"📋 任务描述: {task_description[:100]}{\'...\' if len(task_description) > 100 else \'\'}"\n        )\n\n        try:\n            # 使用RAG增强agent执行任务\n            result = await self.agent.execute_task_with_rag(\n                task_description=task_description, max_iterations=max_iterations\n            )\n\n            # 增强结果信息\n            enhanced_result = self._enhance_result(result, task_description)\n\n            # 记录执行结果\n            if enhanced_result.get("success"):\n                logger.info("🎉 RAG增强任务执行成功!")\n            else:\n                logger.warning("⚠️ RAG增强任务执行部分成功或失败")\n\n            success_count = enhanced_result.get("successful_steps", 0)\n            total_steps = enhanced_result.get("total_steps", 0)\n            relevant_files = enhanced_result.get("relevant_files_analyzed", 0)\n\n            logger.info(f"📈 执行统计: {success_count}/{total_steps} 步骤成功")\n            logger.info(f"🔍 RAG分析: {relevant_files} 个相关文件")\n\n            return enhanced_result\n\n        except Exception as e:\n            logger.error(f"❌ RAG增强任务执行失败: {str(e)}")\n            return {\n                "success": False,\n                "error": str(e),\n                "rag_enhanced": True,\n                "workflow_type": "rag_enhanced",\n            }\n\n    def _enhance_result(\n        self, result: Dict[str, Any], task_description: str\n    ) -> Dict[str, Any]:\n        """增强执行结果信息"""\n        enhanced = {\n            **result,\n            "workflow_type": "rag_enhanced",\n            "repo_path": self.repo_path,\n            "task_description": task_description,\n            "enhancement_features": [\n                "RAG代码检索",\n                "上下文感知规划",\n                "模式一致性验证",\n                "智能代码生成",\n            ],\n        }\n\n        # 添加质量指标\n        if result.get("results"):\n            rag_enhanced_steps = sum(\n                1 for r in result["results"] if r.get("rag_enhanced", False)\n            )\n            enhanced["rag_enhancement_rate"] = (\n                rag_enhanced_steps / len(result["results"]) if result["results"] else 0\n            )\n\n        return enhanced\n\n    async def analyze_codebase(self) -> Dict[str, Any]:\n        """分析代码库结构和模式"""\n        logger.info("🔍 开始分析代码库...")\n\n        try:\n            # 使用agent的内部组件进行分析\n            task_planner = self.agent.task_planner\n\n            # 分析项目结构\n            project_info = await task_planner._analyze_project_structure()\n\n            # 检索关键代码模式（使用通用查询）\n            common_patterns = await task_planner._retrieve_relevant_code(\n                "class function implementation pattern"\n            )\n\n            analysis_result = {\n                "project_structure": project_info,\n                "common_patterns": common_patterns,\n                "analysis_timestamp": asyncio.get_event_loop().time(),\n                "repo_path": self.repo_path,\n            }\n\n            logger.info(f"✅ 代码库分析完成")\n            logger.info(f"   📁 总文件数: {project_info.get(\'total_files\', 0)}")\n            logger.info(\n                f"   🔤 主要语言: {\', \'.join(project_info.get(\'main_languages\', [])[:3])}"\n            )\n            logger.info(f"   📋 发现模式: {len(common_patterns)} 个")\n\n            return analysis_result\n\n        except Exception as e:\n            logger.error(f"❌ 代码库分析失败: {str(e)}")\n            return {"success": False, "error": str(e)}\n\n    async def suggest_improvements(self, focus_area: str = "") -> Dict[str, Any]:\n        """基于RAG分析建议代码改进"""\n        logger.info("💡 生成代码改进建议...")\n\n        try:\n            # 构建改进建议任务\n            improvement_task = f"""\n            基于当前代码库的分析，请提供代码改进建议。\n            {\'重点关注: \' + focus_area if focus_area else \'\'}\n            \n            请分析:\n            1. 代码结构和架构改进机会\n            2. 性能优化建议\n            3. 可维护性提升方案\n            4. 安全性增强建议\n            5. 测试覆盖率改进\n            """\n\n            # 执行分析任务\n            result = await self.execute_task(improvement_task)\n\n            if result.get("success"):\n                logger.info("✅ 改进建议生成成功")\n            else:\n                logger.warning("⚠️ 改进建议生成部分成功")\n\n            return result\n\n        except Exception as e:\n            logger.error(f"❌ 改进建议生成失败: {str(e)}")\n            return {"success": False, "error": str(e)}\n\n    async def execute_refactoring(\n        self, target_files: List[str], refactoring_goals: str\n    ) -> Dict[str, Any]:\n        """执行代码重构任务"""\n        logger.info(f"🔄 开始代码重构...")\n        logger.info(\n            f"📁 目标文件: {\', \'.join(target_files[:3])}{\'...\' if len(target_files) > 3 else \'\'}"\n        )\n\n        try:\n            # 构建重构任务\n            refactoring_task = f"""\n            请对以下文件进行重构:\n            {chr(10).join(f"- {file}" for file in target_files)}\n            \n            重构目标:\n            {refactoring_goals}\n            \n            要求:\n            1. 保持现有功能完整性\n            2. 遵循项目代码风格和模式\n            3. 提高代码可读性和可维护性\n            4. 确保向后兼容性\n            5. 添加必要的测试验证\n            """\n\n            # 执行重构任务\n            result = await self.execute_task(refactoring_task)\n\n            # 增强重构结果\n            if result.get("success"):\n                result["refactoring_files"] = target_files\n                result["refactoring_goals"] = refactoring_goals\n                logger.info("✅ 代码重构完成")\n            else:\n                logger.warning("⚠️ 代码重构部分完成")\n\n            return result\n\n        except Exception as e:\n            logger.error(f"❌ 代码重构失败: {str(e)}")\n            return {\n                "success": False,\n                "error": str(e),\n                "refactoring_files": target_files,\n            }\n\n    async def generate_documentation(self, doc_type: str = "api") -> Dict[str, Any]:\n        """生成项目文档"""\n        logger.info(f"📚 开始生成 {doc_type} 文档...")\n\n        try:\n            # 构建文档生成任务\n            if doc_type.lower() == "api":\n                doc_task = """\n                基于当前代码库生成API文档:\n                1. 分析所有公开的类和函数\n                2. 提取文档字符串和注释\n                3. 生成结构化的API文档\n                4. 包含使用示例和参数说明\n                5. 遵循项目文档风格\n                """\n            elif doc_type.lower() == "architecture":\n                doc_task = """\n                生成项目架构文档:\n                1. 分析项目整体结构\n                2. 识别核心组件和依赖关系\n                3. 生成架构图和说明\n                4. 描述设计模式和最佳实践\n                5. 包含部署和配置说明\n                """\n            else:\n                doc_task = f"""\n                生成 {doc_type} 相关文档:\n                1. 分析相关代码和组件\n                2. 提取关键信息和模式\n                3. 生成结构化文档\n                4. 包含示例和最佳实践\n                """\n\n            # 执行文档生成任务\n            result = await self.execute_task(doc_task)\n\n            if result.get("success"):\n                result["documentation_type"] = doc_type\n                logger.info(f"✅ {doc_type} 文档生成完成")\n            else:\n                logger.warning(f"⚠️ {doc_type} 文档生成部分完成")\n\n            return result\n\n        except Exception as e:\n            logger.error(f"❌ 文档生成失败: {str(e)}")\n            return {"success": False, "error": str(e), "documentation_type": doc_type}\n\n    def get_available_tools(self) -> List[str]:\n        """获取可用工具列表"""\n        return [getattr(tool, "name", str(tool)) for tool in self.code_tools]\n\n    def get_workflow_capabilities(self) -> Dict[str, Any]:\n        """获取工作流能力描述"""\n        return {\n            "core_features": [\n                "RAG增强代码生成",\n                "上下文感知任务规划",\n                "模式一致性保证",\n                "智能代码重构",\n                "自动文档生成",\n            ],\n            "supported_tasks": [\n                "新功能开发",\n                "代码重构",\n                "Bug修复",\n                "性能优化",\n                "文档生成",\n                "架构分析",\n            ],\n            "quality_metrics": ["模式一致性", "代码重用率", "集成质量", "约定遵循率"],\n            "tools_count": len(self.code_tools),\n            "repo_path": self.repo_path,\n        }', 'similarity': 0.8}, {'content': '    async def analyze_codebase(self) -> Dict[str, Any]:\n        """分析代码库结构和模式"""\n        logger.info("🔍 开始分析代码库...")\n\n        try:\n            # 使用agent的内部组件进行分析\n            task_planner = self.agent.task_planner\n\n            # 分析项目结构\n            project_info = await task_planner._analyze_project_structure()\n\n            # 检索关键代码模式（使用通用查询）\n            common_patterns = await task_planner._retrieve_relevant_code(\n                "class function implementation pattern"\n            )\n\n            analysis_result = {\n                "project_structure": project_info,\n                "common_patterns": common_patterns,\n                "analysis_timestamp": asyncio.get_event_loop().time(),\n                "repo_path": self.repo_path,\n            }\n\n            logger.info(f"✅ 代码库分析完成")\n            logger.info(f"   📁 总文件数: {project_info.get(\'total_files\', 0)}")\n            logger.info(\n                f"   🔤 主要语言: {\', \'.join(project_info.get(\'main_languages\', [])[:3])}"\n            )\n            logger.info(f"   📋 发现模式: {len(common_patterns)} 个")\n\n            return analysis_result\n\n        except Exception as e:\n            logger.error(f"❌ 代码库分析失败: {str(e)}")\n            return {"success": False, "error": str(e)}', 'similarity': 0.8}]}
