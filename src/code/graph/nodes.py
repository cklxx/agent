# SPDX-License-Identifier: MIT

import json
import logging
from typing import Literal

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.types import Command
from langchain_core.tools import tool

from src.context.manager import ContextManager
from src.context.rag_context_manager import RAGContextManager
from src.prompts.planner_model import Plan
from src.agents.agents import create_agent
from src.config.agents import AGENT_LLM_MAP
from src.llms.llm import get_llm_by_type
from src.tools import (
    # ä»£ç æ‰§è¡Œå·¥å…·
    python_repl_tool,
    # æœç´¢å’Œç½‘ç»œå·¥å…·
    crawl_tool,
    get_web_search_tool,
    search_location,
    get_route,
    get_nearby_places,
    # ç¬”è®°æœ¬å·¥å…·
    notebook_read,
    notebook_edit_cell,
    # å¯¹è¯ç®¡ç†å·¥å…·
    clear_conversation,
    compact_conversation,
    # æ€è€ƒå·¥å…·
    think,
)
import asyncio
from src.prompts.template import apply_prompt_template

# å¯¼å…¥ä¸Šä¸‹æ–‡ç®¡ç†ç›¸å…³æ¨¡å—
from src.context.intelligent_workspace_analyzer import (
    IntelligentWorkspaceAnalyzer,
)
from src.tools.workspace_tools import get_workspace_tools
from src.utils.json_utils import repair_json_output
from src.code.graph.types import State
from src.utils.simple_token_tracker import SimpleTokenTracker

logger = logging.getLogger(__name__)

# åˆ›å»ºå·¥å…·åç§°åˆ°å·¥å…·å¯¹è±¡çš„æ˜ å°„ï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾
token_tracker = SimpleTokenTracker()
token_tracker.start_session("architect_agent")


def get_workspace_aware_agent_tools(state: State) -> list:
    """
    Helper function to get a complete list of workspace-aware tools for an agent.

    Args:
        state: Current state containing workspace information

    Returns:
        List of tools including both workspace-aware and original tools
    """
    workspace = state.get("workspace", "")
    workspace_tools = get_workspace_tools(workspace)

    other_tools = [
        think,
        crawl_tool,
        get_web_search_tool(3),  # Web search with limit
        search_location,
        get_route,
        get_nearby_places,
        python_repl_tool,
        clear_conversation,
        compact_conversation,
    ]

    return workspace_tools + other_tools


@tool
def plan_tool(
    plan: Plan,
):
    """Plan tool to do plan."""
    return plan


context_manager_cache = None


def update_context(state: State):
    """ä¸Šä¸‹æ–‡èŠ‚ç‚¹ï¼šè´Ÿè´£ç¯å¢ƒæ„ŸçŸ¥å’ŒRAGç´¢å¼•æ„å»º"""
    logger.info("ğŸ” å¯åŠ¨ä¸Šä¸‹æ–‡åˆ†æå’Œç¯å¢ƒæ„ŸçŸ¥...")

    # é€šè¿‡ç³»ç»Ÿè·å–æ‰§è¡Œç¯å¢ƒçš„ä¿¡æ¯
    try:

        # è·å–ä»»åŠ¡æè¿°
        user_messages = state.get("messages", [])
        task_description = user_messages[-1].content

        # åˆå§‹åŒ–æ™ºèƒ½å·¥ä½œåŒºåˆ†æå™¨
        analyzer = IntelligentWorkspaceAnalyzer(state.get("workspace", ""))
        # å†³å®šæ˜¯å¦éœ€è¦æ‰§è¡Œåˆ†æ
        environment_result = asyncio.run(analyzer.perform_environment_analysis())
        environment_info = environment_result["text_summary"]

        if context_manager_cache is None:
            context_manager_cache = RAGContextManager(
                context_manager=ContextManager(),
                repo_path=".",
                use_enhanced_retriever=True,
            )
        context = asyncio.run(context_manager_cache.get_rag_context_summary_text())
        logger.info(f"ğŸ” ä¸Šä¸‹æ–‡: {context}")

        state.update(
            {
                "environment_info": environment_info,
                "task_description": task_description,
            }
        )
        logger.info("âœ… ä¸Šä¸‹æ–‡å‡†å¤‡å®Œæˆ")

    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ ä¸Šä¸‹æ–‡èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯: {error_msg}")


def leader_node(state: State) -> Command[Literal["__end__", "team"]]:
    """é¢†å¯¼èŠ‚ç‚¹ï¼šç†è§£ç”¨æˆ·æ„å›¾, äº§å‡ºè§„åˆ’"""
    logger.info("ğŸ—ï¸ å¼€å§‹è§„åˆ’ä»»åŠ¡...")
    update_context(state)
    plan_iterations = state.get("plan_iterations", 0)
    task_description = state.get("task_description", "Unknown task")

    agent_type = "leader"
    iterations_limit = 4
    if plan_iterations > iterations_limit:
        return Command(
            update={
                "report": (
                    f"Plan iterations limit reached: {iterations_limit} times, please check the plan and observations. {Plan.model_validate(state.get('plan',{})).report}"
                ),
            },
            goto="__end__",
        )
    try:
        # åˆ›å»ºæ¶æ„å¸ˆä»£ç†
        ALL_TOOLS = get_workspace_aware_agent_tools(state)
        agent = create_agent("leader", "leader", ALL_TOOLS, "leader")

        messages = apply_prompt_template(agent_type, state)
        observations = state.get("observations", [])
        plan = state.get("plan", None)
        if plan is not None and len(observations) >= len(plan.steps):
            logger.debug(f"ğŸ” è§‚å¯Ÿ: {observations[-1]}")
            all_observations = ""
            for index, observation in enumerate(observations):
                all_observations += f"# Existing Observations {index}\n\n{observation}"
            messages += [HumanMessage(content=all_observations)]
        logger.debug(f"ğŸ”§ æ„å»ºçš„æ¶ˆæ¯: {messages}")
        agent_input = {
            "messages": messages,
            "plan": plan,
            "observations": observations,
            "environment_info": state.get("environment_info", ""),
            "task_description": task_description,
        }
        # è°ƒç”¨æ¶æ„å¸ˆä»£ç†
        result = agent.invoke(input=agent_input, config={"recursion_limit": 30})

        # ä»å“åº”ä¸­æå–contentå­—æ®µ
        response = result["messages"][-1]
        plan_content = response.content
        logger.debug(f"ğŸ” leaderå“åº”: {response}")
        # è®°å½•tokenä½¿ç”¨æƒ…å†µ

        usage_metadata = response.usage_metadata
        response_metadata = response.response_metadata

        token_tracker.add_usage(
            input_tokens=usage_metadata.get("input_tokens", 0),
            output_tokens=usage_metadata.get("output_tokens", 0),
            model=response_metadata.get("model_name", ""),
        )
        current_plan = state.get("plan", None)
        # è§£æè®¡åˆ’å†…å®¹
        try:
            plan_json = repair_json_output(plan_content)
            logger.info(f"ğŸ” leader plan: {plan_json}")

            current_plan = Plan.model_validate(json.loads(plan_json))
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å†…å®¹: {plan_content}")
            logger.error(f"ä¿®å¤åå†…å®¹: {plan_json}")
            return Command(
                update={
                    "report": f"{plan_content}",
                    "execution_failed": True,
                    "token_usage": token_tracker.get_current_report(),
                },
                goto="__end__",
            )

        if current_plan.has_enough_context:
            return Command(
                update={
                    "report": current_plan.report,
                    "token_usage": token_tracker.get_current_report(),
                },
                goto="__end__",
            )

        return Command(
            update={
                "plan": current_plan,
                "plan_iterations": plan_iterations + 1,
                "token_usage": token_tracker.get_current_report(),
            },
            goto="team",
        )

    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ leaderèŠ‚ç‚¹æ‰§è¡Œé”™è¯¯: {error_msg}")

        return Command(
            update={
                "report": error_msg,
                "execution_failed": True,
                "token_tracker": token_tracker,
            },
            goto="__end__",
        )


def team_node(
    state: State,
) -> Command[Literal["leader", "execute"]]:
    """Research team node that collaborates on tasks."""
    logger.info("Research team is collaborating on tasks.")
    update_context(state)
    current_plan = state.get("plan")
    if not current_plan or not current_plan.steps:
        return Command(
            goto="leader",
        )
    if all(step.execution_res for step in current_plan.steps):
        return Command(goto="leader")
    for step in current_plan.steps:
        if not step.execution_res:
            break
    if step.step_type:
        return Command(goto="execute")
    return Command(goto="leader")


def execute_node(state: State) -> Command[Literal["team"]]:
    """ç¼–ç èŠ‚ç‚¹ï¼šåŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯æ‰§è¡Œä¸»è¦ä»»åŠ¡ï¼Œå¹¶è¾“å‡ºæ‰§è¡Œç»“æœæŠ¥å‘Š"""
    logger.info("ğŸš€ ç¼–ç èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œä»»åŠ¡...")

    current_plan = state.get("plan")
    observations = state.get("observations", [])
    # Find the first unexecuted step
    current_step = None
    completed_steps = []
    for step in current_plan.steps:
        if not step.execution_res:
            current_step = step
            break
        else:
            completed_steps.append(step)

    if not current_step:
        logger.warning("No unexecuted step found")
        return Command(goto="research_team")

    logger.info(f"Executing step: {current_step.title}, agent: execute")

    # Format completed steps information
    completed_steps_info = ""
    if completed_steps:
        completed_steps_info = "# Existing Research Findings\n\n"
        for i, step in enumerate(completed_steps):
            completed_steps_info += f"## Existing Finding {i + 1}: {step.title}\n\n"
            completed_steps_info += f"<finding>\n{step.execution_res}\n</finding>\n\n"

    ALL_TOOLS = get_workspace_aware_agent_tools(state)
    agent = create_agent("execute", "execute", ALL_TOOLS, "execute")
    # Prepare the input for the agent with completed steps info
    agent_input = {
        "messages": (
            apply_prompt_template("execute", state)
            + [
                HumanMessage(
                    content=f"{completed_steps_info}# Current Task\n\n## Title\n\n{current_step.title}\n\n## Description\n\n{current_step.description}\n\n## Locale\n\n{state.get('locale', 'en-US')}"
                )
            ]
        )
    }
    logger.info(f"ğŸ” æ‰§è¡Œä»£ç†èŠ‚ç‚¹è¾“å…¥: {len(str(agent_input))}")
    # Invoke the agent
    default_recursion_limit = 30
    result = agent.invoke(
        input=agent_input, config={"recursion_limit": default_recursion_limit}
    )

    observations = state.get("observations", [])

    response = result["messages"][-1]

    logger.info(f"ğŸ” æ‰§è¡Œä»£ç†èŠ‚ç‚¹æ‰§è¡Œç»“æœ: {response.content}")

    response_content = response.content
    usage_metadata = (
        response.usage_metadata if response.usage_metadata is not None else {}
    )
    response_metadata = (
        response.response_metadata if response.response_metadata is not None else {}
    )
    token_tracker.add_usage(
        input_tokens=usage_metadata.get("input_tokens", 0),
        output_tokens=usage_metadata.get("output_tokens", 0),
        model=response_metadata.get("model_name", ""),
    )
    logger.debug(f"execute full response: {response_content}")
    # Update the step with the execution result
    current_step.execution_res = response_content

    return Command(
        update={
            "observations": observations + [response_content],
            "plan": current_plan,
            "token_usage": token_tracker.get_current_report(),
        },
        goto="team",
    )
