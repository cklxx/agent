# SPDX-License-Identifier: MIT

import json
import logging
import os
from typing import Annotated, Literal

from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool
from langgraph.types import Command, interrupt

from src.code.graph.execute import setup_and_execute_agent_step
from src.tools.maps import search_location_in_city
from src.tools import (
    crawl_tool,
    get_web_search_tool,
    get_retriever_tool,
    python_repl_tool,
    search_location,
    get_route,
    get_nearby_places,
    read_file,
    read_file_lines,
    get_file_info,
    write_file,
    append_to_file,
    create_new_file,
    generate_file_diff,
    execute_terminal_command,
    get_current_directory,
    list_directory_contents,
    execute_command_background,
    get_background_tasks_status,
    terminate_background_task,
    test_service_command,
)

from src.config.agents import AGENT_LLM_MAP
from src.config.configuration import Configuration
from src.llms.llm import get_llm_by_type
from src.prompts.planner_model import Plan, StepType
from src.prompts.template import apply_prompt_template
from src.utils.json_utils import repair_json_output

from .types import State

logger = logging.getLogger(__name__)

# è®¾ç½®æ—¥å¿—
llm_logger = logging.getLogger("llm_planner")


def _clear_report_state(state: State, keep_plan_iterations: bool = True) -> dict:
    """
    é€šç”¨çš„æŠ¥å‘ŠçŠ¶æ€æ¸…ç†å‡½æ•°

    Args:
        state: å½“å‰çŠ¶æ€
        keep_plan_iterations: æ˜¯å¦ä¿æŒè§„åˆ’è¿­ä»£è®¡æ•°

    Returns:
        æ¸…ç†åçš„çŠ¶æ€æ›´æ–°å­—å…¸
    """
    update_dict = {
        "final_report": "",  # æ¸…ç©ºä¹‹å‰çš„æŠ¥å‘Š
        "current_plan": None,  # é‡ç½®å½“å‰è®¡åˆ’
        "observations": [],  # æ¸…ç©ºè§‚å¯Ÿç»“æœ
    }

    if keep_plan_iterations:
        update_dict["plan_iterations"] = state.get("plan_iterations", 0)
    else:
        update_dict["plan_iterations"] = 0

    return update_dict


def _check_reflection_response(response_content: str) -> tuple[bool, dict]:
    """
    é€šç”¨çš„åæ€å“åº”æ£€æŸ¥å‡½æ•°

    Args:
        response_content: LLMçš„åŸå§‹å“åº”å†…å®¹

    Returns:
        (éœ€è¦é‡æ–°è§„åˆ’, è§£æçš„åæ€æ•°æ®)
    """
    try:
        # ä½¿ç”¨é€šç”¨çš„JSONä¿®å¤å·¥å…·
        repaired_json = repair_json_output(response_content)
        parsed_response = json.loads(repaired_json)

        if parsed_response.get("reflection_result") == "need_replanning":
            return True, parsed_response

    except (json.JSONDecodeError, KeyError, ValueError) as e:
        logger.debug(f"éJSONå“åº”æˆ–è§£æé”™è¯¯ï¼Œä½œä¸ºæ­£å¸¸æŠ¥å‘Šå¤„ç†: {e}")

    return False, {}


@tool
def handoff_to_planner(
    task_title: Annotated[str, "The title of the task to be handed off."],
    locale: Annotated[str, "The user's detected language locale (e.g., en-US, zh-CN)."],
):
    """Handoff to planner agent to do plan."""
    # This tool is not returning anything: we're just using it
    # as a way for LLM to signal that it needs to hand off to planner agent
    return


@tool
def execute_simple_task(
    task_description: Annotated[
        str, "Description of the simple task to be executed directly."
    ],
    locale: Annotated[str, "The user's detected language locale (e.g., en-US, zh-CN)."],
):
    """Execute simple, straightforward tasks directly without planning overhead."""
    # This tool is not returning anything: we're just using it
    # as a way for LLM to signal that it wants to execute a simple task directly
    return


def context_node(
    state: State, config: RunnableConfig
) -> Command[Literal["code_coordinator"]]:
    """Context manager node - åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å’Œç¯å¢ƒä¿¡æ¯"""
    logger.info("ğŸ”§ ContextèŠ‚ç‚¹ï¼šåˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å’Œç¯å¢ƒä¿¡æ¯")

    # è·å–é…ç½®ä¿¡æ¯
    configurable = Configuration.from_runnable_config(config)

    # åˆå§‹åŒ–ç¯å¢ƒä¿¡æ¯
    environment_info = {
        "current_directory": os.getcwd(),
        "python_version": (
            f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}"
        ),
        "platform": os.name,
    }

    # åˆå§‹åŒ–RAGä¸Šä¸‹æ–‡ï¼ˆå¦‚æœé…ç½®äº†èµ„æºï¼‰
    rag_context = ""
    if configurable.resources:
        rag_context = "Available RAG resources: " + ", ".join(
            [f"{res.title} ({res.description})" for res in configurable.resources]
        )

    logger.info(f"âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œå·¥ä½œç›®å½•: {environment_info['current_directory']}")

    return Command(
        update={
            "environment_info": environment_info,
            "rag_context": rag_context,
            "locale": state.get("locale", "zh-CN"),  # é»˜è®¤ä¸­æ–‡
            "resources": configurable.resources,
        },
        goto="code_coordinator",
    )


def code_coordinator_node(
    state: State, config: RunnableConfig
) -> Command[Literal["code_task_planner", "code_coder", "code_reporter", "__end__"]]:
    """Coordinator node - æ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©æ‰§è¡Œplanneræˆ–ç»“æŸ"""
    logger.info("ğŸ¯ CoordinatorèŠ‚ç‚¹ï¼šåˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨")

    configurable = Configuration.from_runnable_config(config)
    messages = apply_prompt_template("code_coordinator", state)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å®Œæ•´çš„æœ€ç»ˆæŠ¥å‘Š
    if state.get("final_report") and state.get("final_report").strip():
        logger.info("âœ… æ£€æµ‹åˆ°æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆï¼Œå‡†å¤‡ç»“æŸæµç¨‹")
        return Command(goto="__end__")

    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰è®¡åˆ’æ­¥éª¤
    current_plan = state.get("current_plan")
    if current_plan and hasattr(current_plan, "steps") and current_plan.steps:
        all_completed = all(
            hasattr(step, "execution_res") and step.execution_res
            for step in current_plan.steps
        )
        if all_completed:
            logger.info("ğŸ“‹ æ‰€æœ‰è®¡åˆ’æ­¥éª¤å·²å®Œæˆï¼Œè·³è½¬åˆ°reporterç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            return Command(goto="code_reporter")

    # è°ƒç”¨LLMå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
    response = (
        get_llm_by_type(AGENT_LLM_MAP["coordinator"])
        .bind_tools([handoff_to_planner, execute_simple_task])
        .invoke(messages)
    )

    locale = state.get("locale", "zh-CN")

    if len(response.tool_calls) > 0:
        tool_name = response.tool_calls[0]["name"]
        if tool_name == "handoff_to_planner":
            logger.info("ğŸ§  Coordinatorå†³å®šå¯åŠ¨plannerè¿›è¡Œä»»åŠ¡è§„åˆ’")
            goto = "code_task_planner"
        elif tool_name == "execute_simple_task":
            logger.info("âš¡ Coordinatorå†³å®šç›´æ¥æ‰§è¡Œç®€å•ä»»åŠ¡")
            goto = "code_coder"
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥å·¥å…·è°ƒç”¨: {tool_name}ï¼Œé»˜è®¤ç»“æŸæµç¨‹")
            goto = "__end__"
    else:
        logger.info("ğŸ Coordinatorå†³å®šç»“æŸå·¥ä½œæµç¨‹")
        goto = "__end__"

    return Command(
        update={"locale": locale, "resources": configurable.resources},
        goto=goto,
    )


def code_task_planner_node(
    state: State, config: RunnableConfig
) -> Command[Literal["code_team", "code_reporter"]]:
    """Planner node - è¾“å‡ºè®¡åˆ’ååˆ°teamèŠ‚ç‚¹"""
    logger.info("ğŸ§  PlannerèŠ‚ç‚¹ï¼šç”Ÿæˆè¯¦ç»†æ‰§è¡Œè®¡åˆ’")

    configurable = Configuration.from_runnable_config(config)
    plan_iterations = state.get("plan_iterations", 0)
    messages = apply_prompt_template("code_task_planner", state, configurable)

    # è®°å½•è§„åˆ’ç›¸å…³çš„è¾“å…¥ä¿¡æ¯
    if state.get("messages"):
        user_query = state["messages"][-1].content if state["messages"] else "æœªçŸ¥æŸ¥è¯¢"
        llm_logger.info(
            f"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query[:80]}{'...' if len(user_query) > 80 else ''}"
        )

    logger.debug(f"è§„åˆ’è¿­ä»£æ¬¡æ•°: {plan_iterations}")

    # æ·»åŠ èƒŒæ™¯è°ƒç ”ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    if (
        plan_iterations == 0
        and state.get("enable_background_investigation")
        and state.get("background_investigation_results")
    ):
        messages += [
            {
                "role": "user",
                "content": (
                    "background investigation results of user query:\n"
                    + state["background_investigation_results"]
                    + "\n"
                ),
            }
        ]
        logger.debug("å·²æ·»åŠ èƒŒæ™¯è°ƒç ”ç»“æœåˆ°è§„åˆ’ä¸Šä¸‹æ–‡")

    # é€‰æ‹©åˆé€‚çš„LLM
    if AGENT_LLM_MAP["planner"] == "basic":
        llm = get_llm_by_type(AGENT_LLM_MAP["planner"]).with_structured_output(
            Plan,
            method="json_mode",
        )
    else:
        llm = get_llm_by_type(AGENT_LLM_MAP["planner"])

    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è§„åˆ’è¿­ä»£æ¬¡æ•°
    if plan_iterations >= configurable.max_plan_iterations:
        logger.warning(
            f"âš ï¸ è§„åˆ’è¿­ä»£è¾¾åˆ°ä¸Šé™ ({configurable.max_plan_iterations})ï¼Œè·³è½¬åˆ°reporter"
        )
        return Command(goto="code_reporter")

    llm_logger.info("ğŸ§  LLMæ­£åœ¨ç”Ÿæˆæ‰§è¡Œè®¡åˆ’...")

    # ç”Ÿæˆè®¡åˆ’
    full_response = ""
    curr_plan = None

    if AGENT_LLM_MAP["planner"] == "basic":
        response = llm.invoke(messages)
        # å¯¹äºstructured outputï¼Œå“åº”æ˜¯å·²éªŒè¯çš„Planå¯¹è±¡
        if hasattr(response, "model_dump"):
            # è¿™æ˜¯ä¸€ä¸ªPlanå¯¹è±¡ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å®ƒåŒ…å«localeå­—æ®µ
            curr_plan_dict = response.model_dump()
            # ç¡®ä¿åŒ…å«localeå­—æ®µ
            if "locale" not in curr_plan_dict:
                curr_plan_dict["locale"] = state.get("locale", "zh-CN")
            # é‡æ–°åˆ›å»ºPlanå¯¹è±¡ä»¥ä¾¿åç»­ä½¿ç”¨
            curr_plan = Plan.model_validate(curr_plan_dict)
            full_response = json.dumps(curr_plan_dict, indent=4, ensure_ascii=False)
        else:
            # å¤‡ç”¨ï¼šå¦‚æœè¿”å›çš„æ˜¯JSONå­—ç¬¦ä¸²
            full_response = response.model_dump_json(indent=4, exclude_none=True)
            curr_plan_dict = json.loads(repair_json_output(full_response))
            if "locale" not in curr_plan_dict:
                curr_plan_dict["locale"] = state.get("locale", "zh-CN")
            curr_plan = Plan.model_validate(curr_plan_dict)
    else:
        response = llm.stream(messages)
        for chunk in response:
            full_response += chunk.content

        # è§£æstreamingå“åº”
        try:
            curr_plan_dict = json.loads(repair_json_output(full_response))
            # ç¡®ä¿åŒ…å«å¿…éœ€çš„localeå­—æ®µ
            if "locale" not in curr_plan_dict:
                curr_plan_dict["locale"] = state.get("locale", "zh-CN")
            # åˆ›å»ºPlanå¯¹è±¡
            curr_plan = Plan.model_validate(curr_plan_dict)
        except json.JSONDecodeError:
            logger.warning("âš ï¸ è§„åˆ’è¾“å‡ºè§£æå¤±è´¥ï¼šJSONæ ¼å¼é”™è¯¯")
            if plan_iterations > 0:
                return Command(goto="code_reporter")
            else:
                return Command(goto="__end__")
        except Exception as e:
            logger.warning(f"âš ï¸ Planæ¨¡å‹éªŒè¯å¤±è´¥ï¼š{e}")
            if plan_iterations > 0:
                return Command(goto="code_reporter")
            else:
                return Command(goto="__end__")

    logger.debug(
        f"Planner response: {full_response[:200]}{'...' if len(full_response) > 200 else ''}"
    )

    if curr_plan and hasattr(curr_plan, "steps") and curr_plan.steps:
        # è®°å½•è§„åˆ’çš„æ ¸å¿ƒä¿¡æ¯
        steps = curr_plan.steps
        llm_logger.info(f"âœ… ç”Ÿæˆ {len(steps)} ä¸ªæ‰§è¡Œæ­¥éª¤")

        # è¯¦ç»†è®°å½•æ­¥éª¤ä¿¡æ¯
        logger.debug("è§„åˆ’æ­¥éª¤è¯¦æƒ…:")
        for i, step in enumerate(steps, 1):
            step_type = step.step_type
            title = step.title
            description = step.description
            logger.debug(f"  {i}. [{step_type.upper()}] {title}")
            logger.debug(
                f"     ğŸ“– {description[:60]}{'...' if len(description) > 60 else ''}"
            )
    else:
        logger.warning("âš ï¸ æ— æ³•è§£æè®¡åˆ’å†…å®¹")
        if plan_iterations > 0:
            return Command(goto="code_reporter")
        else:
            return Command(goto="__end__")

    # æ­£å¸¸æƒ…å†µï¼šéœ€è¦teamæ‰§è¡Œå…·ä½“ä»»åŠ¡
    logger.info("ğŸ“‹ è®¡åˆ’ç”Ÿæˆå®Œæˆï¼Œè½¬äº¤ç»™teamæ‰§è¡Œ")

    return Command(
        update={
            "messages": [AIMessage(content=full_response, name="planner")],
            "current_plan": curr_plan,
            "plan_iterations": plan_iterations + 1,
        },
        goto="code_team",
    )


def code_team_node(
    state: State,
) -> Command[Literal["code_researcher", "code_coder", "code_reporter"]]:
    """Team node - æ ¹æ®ä»»åŠ¡å’ŒçŠ¶æ€é€‰æ‹©researcheræˆ–coder"""
    logger.info("ğŸ‘¥ TeamèŠ‚ç‚¹ï¼šåˆ†æå½“å‰ä»»åŠ¡ï¼Œé€‰æ‹©åˆé€‚çš„æ‰§è¡Œè§’è‰²")

    current_plan = state.get("current_plan")
    if not current_plan or not hasattr(current_plan, "steps"):
        logger.warning("âš ï¸ æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’ï¼Œè¿”å›reporter")
        return Command(goto="code_reporter")

    steps = current_plan.steps
    if not steps:
        logger.warning("âš ï¸ è®¡åˆ’ä¸­æ²¡æœ‰æ­¥éª¤ï¼Œè¿”å›reporter")
        return Command(goto="code_reporter")

    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆ
    completed_steps = [
        step for step in steps if hasattr(step, "execution_res") and step.execution_res
    ]

    if len(completed_steps) == len(steps):
        logger.info("âœ… æ‰€æœ‰è®¡åˆ’æ­¥éª¤å·²å®Œæˆï¼Œè½¬åˆ°reporterç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        return Command(goto="code_reporter")

    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªæœªæ‰§è¡Œçš„æ­¥éª¤
    current_step = None
    for step in steps:
        if not (hasattr(step, "execution_res") and step.execution_res):
            current_step = step
            break

    if not current_step:
        logger.info("ğŸ“‹ æ²¡æœ‰å¾…æ‰§è¡Œæ­¥éª¤ï¼Œè½¬åˆ°reporter")
        return Command(goto="code_reporter")

    # æ ¹æ®æ­¥éª¤ç±»å‹é€‰æ‹©æ‰§è¡Œè€…
    step_type = getattr(current_step, "step_type", None)
    step_title = getattr(current_step, "title", "æœªçŸ¥ä»»åŠ¡")

    if step_type == StepType.RESEARCH:
        logger.info(f"ğŸ” é€‰æ‹©researcheræ‰§è¡Œç ”ç©¶ä»»åŠ¡: {step_title}")
        return Command(goto="code_researcher")
    elif step_type == StepType.PROCESSING:
        logger.info(f"ğŸ’» é€‰æ‹©coderæ‰§è¡Œç¼–ç¨‹ä»»åŠ¡: {step_title}")
        return Command(goto="code_coder")
    else:
        # é»˜è®¤æƒ…å†µï¼šåŸºäºä»»åŠ¡æè¿°æ™ºèƒ½é€‰æ‹©
        description = getattr(current_step, "description", "").lower()
        if any(
            keyword in description
            for keyword in [
                "æœç´¢",
                "è°ƒç ”",
                "æŸ¥æ‰¾",
                "æ”¶é›†",
                "åˆ†æèµ„æ–™",
                "research",
                "search",
            ]
        ):
            logger.info(f"ğŸ” åŸºäºæè¿°é€‰æ‹©researcher: {step_title}")
            return Command(goto="code_researcher")
        elif any(
            keyword in description
            for keyword in [
                "ç¼–ç¨‹",
                "ä»£ç ",
                "å®ç°",
                "å¼€å‘",
                "è„šæœ¬",
                "code",
                "implement",
                "develop",
            ]
        ):
            logger.info(f"ğŸ’» åŸºäºæè¿°é€‰æ‹©coder: {step_title}")
            return Command(goto="code_coder")
        else:
            # é»˜è®¤é€‰æ‹©researcher
            logger.info(f"ğŸ” é»˜è®¤é€‰æ‹©researcheræ‰§è¡Œ: {step_title}")
            return Command(goto="code_researcher")


async def code_researcher_node(
    state: State, config: RunnableConfig
) -> Command[Literal["code_team", "code_coordinator"]]:
    """Researcher node - ä½¿ç”¨å·¥å…·æŸ¥æ‰¾èµ„æ–™ï¼Œæ ¹æ®ç ”ç©¶ç»“æœå†³å®šè¿”å›teamæˆ–coordinator"""
    logger.info("ğŸ” ResearcherèŠ‚ç‚¹ï¼šæœç´¢å’Œæ”¶é›†ä¿¡æ¯")

    configurable = Configuration.from_runnable_config(config)

    # ä¸ºresearcheré…ç½®ä¸“ç”¨å·¥å…·
    research_tools = [
        get_web_search_tool(configurable.max_search_results),
        crawl_tool,
        search_location,
        search_location_in_city,
        get_route,
        get_nearby_places,  # RAGæ£€ç´¢å·¥å…·
        # æ·»åŠ æ–‡ä»¶è¯»å–å·¥å…·ç”¨äºåˆ†æç°æœ‰èµ„æ–™
        read_file,
        read_file_lines,
        get_file_info,
    ]
    resources = state.get("resources", [])
    if resources:
        retriever_tool = get_retriever_tool(resources)
        if retriever_tool:
            research_tools.append(retriever_tool)
    result = await setup_and_execute_agent_step(
        state, config, "code_researcher", research_tools
    )

    if result.update.get("goto") == "code_coordinator":
        logger.info("ğŸ“‹ ç ”ç©¶ç»“æœè¡¨æ˜éœ€è¦é‡æ–°è§„åˆ’ï¼Œè¿”å›coordinatorèŠ‚ç‚¹")
        return Command(update=result.update, goto="code_coordinator")
    else:
        logger.info("âœ… Researcherä»»åŠ¡å®Œæˆï¼Œè¿”å›teamèŠ‚ç‚¹ç»§ç»­æ‰§è¡Œ")
        return Command(update=result.update, goto="code_team")


async def code_coder_node(
    state: State, config: RunnableConfig
) -> Command[Literal["code_team"]]:
    """Coder node - ä½¿ç”¨å·¥å…·æŸ¥çœ‹ä»£ç ã€ç¼–å†™ä»£ç ã€è¿è¡Œå‘½ä»¤è¡Œï¼Œæ‰§è¡Œå®Œè½¬åˆ°team"""
    logger.info("ğŸ’» CoderèŠ‚ç‚¹ï¼šä»£ç åˆ†æå’Œå¼€å‘")

    # ä¸ºcoderé…ç½®ä¸“ç”¨å·¥å…·
    coding_tools = [
        # æ–‡ä»¶æ“ä½œå·¥å…·
        read_file,
        read_file_lines,
        get_file_info,
        write_file,
        append_to_file,
        create_new_file,
        generate_file_diff,
        # ç»ˆç«¯æ“ä½œå·¥å…·
        execute_terminal_command,
        get_current_directory,
        list_directory_contents,
        execute_command_background,
        get_background_tasks_status,
        terminate_background_task,
        test_service_command,
        # ä»£ç æ‰§è¡Œå·¥å…·
        python_repl_tool,
    ]
    resources = state.get("resources", [])
    if resources:
        retriever_tool = get_retriever_tool(resources)
        if retriever_tool:
            coding_tools.append(retriever_tool)

    result = await setup_and_execute_agent_step(
        state, config, "code_coder", coding_tools
    )

    # æ‰§è¡Œå®Œæˆåè¿”å›teamè¿›è¡Œä¸‹ä¸€è½®å†³ç­–
    logger.info("âœ… Coderä»»åŠ¡å®Œæˆï¼Œè¿”å›teamèŠ‚ç‚¹")
    return Command(update=result.update, goto="code_team")


def code_reporter_node(state: State) -> Command[Literal["code_coordinator", "__end__"]]:
    """Reporter node - è¾“å‡ºæœ€ç»ˆæŠ¥å‘Šï¼ŒåŒ…å«åæ€åŠŸèƒ½"""
    logger.info("ğŸ“Š ReporterèŠ‚ç‚¹ï¼šç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¹¶è¿›è¡Œåæ€è¯„ä¼°")

    current_plan = state.get("current_plan")

    # æ„å»ºæŠ¥å‘Šè¾“å…¥
    input_ = {
        "messages": [
            HumanMessage(
                f"# ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š\n\n## ä»»åŠ¡æ ‡é¢˜\n\n{getattr(current_plan, 'title', 'æœªçŸ¥ä»»åŠ¡')}\n\n## ä»»åŠ¡æè¿°\n\n{getattr(current_plan, 'thought', 'æ— æè¿°')}"
            )
        ],
        "locale": state.get("locale", "zh-CN"),
    }

    # åº”ç”¨reporteræ¨¡æ¿
    invoke_messages = apply_prompt_template("code_reporter", input_)
    observations = state.get("observations", [])

    # æ·»åŠ æ ¼å¼è¦æ±‚å’Œåæ€æŒ‡å¯¼
    invoke_messages.append(
        HumanMessage(
            content='é‡è¦æç¤ºï¼šè¯·é¦–å…ˆè¿›è¡Œåæ€è¯„ä¼°ï¼\n\n1. ä»”ç»†è¯„ä¼°ä»»åŠ¡å®Œæˆè´¨é‡å’Œæµ‹è¯•ç»“æœ\n2. å¦‚æœå‘ç°é‡å¤§é—®é¢˜ï¼Œè¯·è¿”å›JSONæ ¼å¼çš„é‡æ–°è§„åˆ’è¯·æ±‚\n3. åªæœ‰åœ¨è´¨é‡è¯„ä¼°é€šè¿‡åï¼Œæ‰ç”Ÿæˆå®Œæ•´çš„MarkdownæŠ¥å‘Š\n\nå¦‚æœéœ€è¦é‡æ–°è§„åˆ’ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š\n```json\n{\n  "reflection_result": "need_replanning",\n  "issues_identified": ["é—®é¢˜æè¿°1", "é—®é¢˜æè¿°2"],\n  "suggested_improvements": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],\n  "reasoning": "è¯¦ç»†è¯´æ˜åŸå› "\n}\n```\n\nå¦‚æœè´¨é‡è¯„ä¼°é€šè¿‡ï¼Œè¯·ç”Ÿæˆå®Œæ•´çš„MarkdownæŠ¥å‘Šï¼ŒåŒ…å«\'åæ€ä¸è¯„ä¼°\'ç« èŠ‚ã€‚',
            name="system",
        )
    )

    # æ·»åŠ æ‰€æœ‰è§‚å¯Ÿç»“æœ
    for i, observation in enumerate(observations, 1):
        invoke_messages.append(
            HumanMessage(
                content=f"æ‰§è¡Œæ­¥éª¤ {i} çš„ç»“æœï¼š\n\n{observation}",
                name="observation",
            )
        )

    logger.debug(f"Reporterè¾“å…¥æ¶ˆæ¯æ•°é‡: {len(invoke_messages)}")

    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    response = get_llm_by_type(AGENT_LLM_MAP["reporter"]).invoke(invoke_messages)
    response_content = response.content

    logger.debug(
        f"ReporteråŸå§‹å“åº”: {response_content[:200]}{'...' if len(response_content) > 200 else ''}"
    )

    # ä½¿ç”¨é€šç”¨å‡½æ•°æ£€æŸ¥æ˜¯å¦æ˜¯é‡æ–°è§„åˆ’è¯·æ±‚
    need_replanning, reflection_data = _check_reflection_response(response_content)

    if need_replanning:
        logger.info("ğŸ”„ Reporteræ£€æµ‹åˆ°é—®é¢˜ï¼Œè¯·æ±‚é‡æ–°è§„åˆ’")

        # è®°å½•æ£€æµ‹åˆ°çš„é—®é¢˜
        issues = reflection_data.get("issues_identified", [])
        improvements = reflection_data.get("suggested_improvements", [])
        reasoning = reflection_data.get("reasoning", "æœªæä¾›è¯¦ç»†åŸå› ")

        logger.info(f"å‘ç°çš„é—®é¢˜: {', '.join(issues)}")
        logger.info(f"å»ºè®®æ”¹è¿›: {', '.join(improvements)}")
        logger.info(f"é‡æ–°è§„åˆ’åŸå› : {reasoning}")

        # æ„å»ºé‡æ–°è§„åˆ’æ¶ˆæ¯
        replanning_message = f"## è´¨é‡è¯„ä¼°åé¦ˆ\n\n"
        replanning_message += f"**è¯„ä¼°ç»“æœ**: éœ€è¦é‡æ–°è§„åˆ’\n\n"
        replanning_message += f"**å‘ç°çš„é—®é¢˜**:\n"
        for issue in issues:
            replanning_message += f"- {issue}\n"
        replanning_message += f"\n**å»ºè®®æ”¹è¿›æ–¹å‘**:\n"
        for improvement in improvements:
            replanning_message += f"- {improvement}\n"
        replanning_message += f"\n**è¯¦ç»†åŸå› **: {reasoning}\n"

        # ä½¿ç”¨é€šç”¨å‡½æ•°å®Œæ•´æ¸…ç†ä¹‹å‰çš„çŠ¶æ€å¹¶é‡ç½®
        update_dict = _clear_report_state(state, keep_plan_iterations=True)
        update_dict["messages"] = [
            AIMessage(content=replanning_message, name="reporter")
        ]

        return Command(
            update=update_dict, goto="code_coordinator"  # è¿”å›coordinatoré‡æ–°è§„åˆ’
        )

    # æ­£å¸¸æƒ…å†µï¼šç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    logger.info("âœ… æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    logger.debug(f"æŠ¥å‘Šé•¿åº¦: {len(response_content)} å­—ç¬¦")

    return Command(update={"final_report": response_content}, goto="__end__")


def human_feedback_node(
    state,
) -> Command[Literal["code_task_planner", "code_team", "code_reporter", "__end__"]]:
    """äººå·¥åé¦ˆèŠ‚ç‚¹ï¼ˆæ ¹æ®éœ€è¦å¯ä»¥æ‰©å±•ï¼‰"""
    current_plan = state.get("current_plan", "")
    auto_accepted_plan = state.get("auto_accepted_plan", False)

    if not auto_accepted_plan:
        feedback = interrupt("è¯·å®¡æ ¸è®¡åˆ’ã€‚")

        if feedback and str(feedback).upper().startswith("[EDIT_PLAN]"):
            logger.info("ç”¨æˆ·è¦æ±‚ç¼–è¾‘è®¡åˆ’")
            return Command(goto="planner")
        elif feedback and str(feedback).upper().startswith("[ACCEPT]"):
            logger.info("ç”¨æˆ·æ¥å—è®¡åˆ’")
            return Command(update={"auto_accepted_plan": True}, goto="team")
        else:
            logger.info("è®¡åˆ’è¢«æ‹’ç»ï¼Œç»“æŸæµç¨‹")
            return Command(goto="__end__")
    else:
        logger.info("è®¡åˆ’è‡ªåŠ¨æ¥å—")
        return Command(goto="team")
