"""
æ™ºèƒ½å·¥ä½œåŒºåˆ†æå™¨ - é›†æˆLLMå†³ç­–çš„å·¥ä½œåŒºçŠ¶æ€ç®¡ç†
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
from pathlib import Path

from .workspace_state_manager import WorkspaceStateManager, WorkspaceAnalysis
from ..llms.llm import get_llm_by_type
from ..prompts import apply_prompt_template
from ..rag.code_indexer import GitignoreParser

logger = logging.getLogger(__name__)


class IntelligentWorkspaceAnalyzer:
    """æ™ºèƒ½å·¥ä½œåŒºåˆ†æå™¨"""

    def __init__(self, workspace_path: str, llm_type: str = "basic"):
        self.workspace_path = workspace_path
        self.state_manager = WorkspaceStateManager(workspace_path)
        self.llm = get_llm_by_type(llm_type)
        # é›†æˆ GitignoreParser ä»¥æ”¯æŒ .gitignore æ–‡ä»¶
        self.gitignore_parser = GitignoreParser(workspace_path)

        logger.info(f"æ™ºèƒ½å·¥ä½œåŒºåˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼š{workspace_path}")

    async def should_perform_analysis(
        self, task_description: str
    ) -> Tuple[bool, bool, Dict[str, Any]]:
        """
        æ™ºèƒ½å†³ç­–æ˜¯å¦éœ€è¦æ‰§è¡Œç¯å¢ƒåˆ†æå’ŒRAGç´¢å¼•

        Args:
            task_description: ç”¨æˆ·ä»»åŠ¡æè¿°

        Returns:
            (should_analyze_env, should_build_rag, decision_context)
        """
        # è·å–å·¥ä½œåŒºçŠ¶æ€ä¸Šä¸‹æ–‡
        workspace_context = self.state_manager.get_context_for_llm()

        # å¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œç›´æ¥æ‰§è¡Œåˆ†æ
        if workspace_context["workspace_status"]["is_first_run"]:
            logger.info("é¦–æ¬¡è¿è¡Œï¼Œç›´æ¥æ‰§è¡Œå®Œæ•´åˆ†æ")
            return (
                True,
                True,
                {
                    "decision_type": "first_run",
                    "reasoning": "é¦–æ¬¡åœ¨æ­¤å·¥ä½œåŒºè¿è¡Œï¼Œéœ€è¦å®Œæ•´çš„ç¯å¢ƒæ¢æµ‹å’ŒRAGç´¢å¼•æ„å»º",
                    "workspace_context": workspace_context,
                },
            )

        # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
        try:
            decision_result = await self._llm_decide_analysis(
                task_description, workspace_context
            )

            should_analyze_env = decision_result.get("analyze_environment", False)
            should_build_rag = decision_result.get("build_rag_index", False)

            logger.info(
                f"LLMå†³ç­–ç»“æœ: ç¯å¢ƒåˆ†æ={should_analyze_env}, RAGç´¢å¼•={should_build_rag}"
            )

            return (
                should_analyze_env,
                should_build_rag,
                {
                    "decision_type": "llm_decision",
                    "reasoning": decision_result.get("reasoning", "LLMæ™ºèƒ½å†³ç­–"),
                    "confidence": decision_result.get("confidence", 0.5),
                    "workspace_context": workspace_context,
                    "llm_response": decision_result,
                },
            )

        except Exception as e:
            logger.error(f"LLMå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥: {e}")

            # å›é€€åˆ°åŸºäºè§„åˆ™çš„å†³ç­–
            should_analyze_env = (
                self.state_manager.should_perform_environment_analysis()
            )
            should_build_rag = self.state_manager.should_perform_rag_indexing()

            return (
                should_analyze_env,
                should_build_rag,
                {
                    "decision_type": "fallback_rules",
                    "reasoning": "LLMå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„é»˜è®¤ç­–ç•¥",
                    "workspace_context": workspace_context,
                    "error": str(e),
                },
            )

    async def _llm_decide_analysis(
        self, task_description: str, workspace_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–"""

        # æ„å»ºå†³ç­–æç¤º
        decision_prompt = apply_prompt_template(
            "intelligent_workspace_decision",
            {
                "task_description": task_description,
                "workspace_status": workspace_context["workspace_status"],
                "analysis_history": workspace_context["analysis_history"],
                "recommendations": workspace_context["recommendations"],
                "current_time": datetime.now().isoformat(),
            },
        )

        # è°ƒç”¨LLMè¿›è¡Œå†³ç­–
        messages = [
            {"role": "system", "content": decision_prompt[0]["content"]},
            {
                "role": "user",
                "content": (
                    f"ä»»åŠ¡æè¿°ï¼š{task_description}\n\nè¯·æ ¹æ®ä¸Šè¿°å·¥ä½œåŒºçŠ¶æ€ä¿¡æ¯ï¼Œæ™ºèƒ½å†³ç­–æ˜¯å¦éœ€è¦æ‰§è¡Œç¯å¢ƒåˆ†æå’ŒRAGç´¢å¼•æ„å»ºã€‚"
                ),
            },
        ]

        response = await self.llm.agenerate(messages)

        # è§£æLLMå“åº”
        return self._parse_llm_decision(response)

    def _parse_llm_decision(self, llm_response: str) -> Dict[str, Any]:
        """è§£æLLMçš„å†³ç­–å“åº”"""
        try:
            # ç®€å•çš„å“åº”è§£æï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›ï¼‰
            response_lower = llm_response.lower()

            # æ£€æµ‹ç¯å¢ƒåˆ†æå†³ç­–
            analyze_env = any(
                keyword in response_lower
                for keyword in [
                    "éœ€è¦ç¯å¢ƒåˆ†æ",
                    "æ‰§è¡Œç¯å¢ƒåˆ†æ",
                    "ç¯å¢ƒæ¢æµ‹",
                    "analyze environment",
                    "environment analysis",
                ]
            )

            # æ£€æµ‹RAGç´¢å¼•å†³ç­–
            build_rag = any(
                keyword in response_lower
                for keyword in [
                    "éœ€è¦ragç´¢å¼•",
                    "æ„å»ºç´¢å¼•",
                    "å»ºç«‹ç´¢å¼•",
                    "build rag",
                    "rag index",
                    "code index",
                ]
            )

            # æ£€æµ‹è·³è¿‡ä¿¡å·
            skip_signals = ["è·³è¿‡", "ä¸éœ€è¦", "skip", "no need", "unnecessary"]
            if any(signal in response_lower for signal in skip_signals):
                if "ç¯å¢ƒ" in response_lower or "environment" in response_lower:
                    analyze_env = False
                if (
                    "rag" in response_lower
                    or "ç´¢å¼•" in response_lower
                    or "index" in response_lower
                ):
                    build_rag = False

            # æå–ç½®ä¿¡åº¦ï¼ˆç®€å•ä¼°ç®—ï¼‰
            confidence = (
                0.8
                if ("å»ºè®®" in response_lower or "recommend" in response_lower)
                else 0.6
            )

            return {
                "analyze_environment": analyze_env,
                "build_rag_index": build_rag,
                "reasoning": llm_response.strip(),
                "confidence": confidence,
            }

        except Exception as e:
            logger.warning(f"è§£æLLMå†³ç­–å“åº”å¤±è´¥: {e}")
            return {
                "analyze_environment": False,
                "build_rag_index": False,
                "reasoning": f"è§£æå¤±è´¥: {str(e)}",
                "confidence": 0.0,
            }

    async def perform_environment_analysis(self) -> Dict[str, Any]:
        """æ‰§è¡Œç¯å¢ƒåˆ†æ"""
        logger.info("å¼€å§‹æ‰§è¡Œç¯å¢ƒåˆ†æ...")

        try:
            # åˆ†æé¡¹ç›®ç»“æ„
            project_structure = await self._analyze_project_structure()

            # åˆ†æç¯å¢ƒä¿¡æ¯
            environment_info = await self._analyze_environment(project_structure)

            # ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„ç¯å¢ƒåˆ†ææŠ¥å‘Š
            text_summary = self._generate_text_summary(
                project_structure, environment_info
            )

            logger.info("ç¯å¢ƒåˆ†æå®Œæˆ")
            return {
                "project_structure": project_structure,
                "environment_info": environment_info,
                "text_summary": text_summary,  # æ–°å¢ï¼šæ–‡æœ¬æ ¼å¼æ‘˜è¦
                "success": True,
            }

        except Exception as e:
            logger.error(f"ç¯å¢ƒåˆ†æå¤±è´¥: {e}")
            return {
                "project_structure": {},
                "environment_info": {},
                "text_summary": f"ç¯å¢ƒåˆ†æå¤±è´¥: {str(e)}",
                "success": False,
                "error": str(e),
            }

    async def _analyze_project_structure(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç»“æ„ï¼Œæ”¯æŒ .gitignore è§„åˆ™"""
        workspace_path = Path(self.workspace_path)
        structure_info = {
            "total_files": 0,
            "total_directories": 0,
            "file_types": {},
            "config_files": [],
            "directories": [],
            "directory_structure": {},  # æ–°å¢ï¼šè¯¦ç»†çš„ç›®å½•ç»“æ„
            "main_languages": [],
            "gitignore_excluded_count": 0,  # æ–°å¢ï¼šè¢« gitignore æ’é™¤çš„æ–‡ä»¶æ•°é‡
        }

        # åŸºç¡€æ’é™¤ç›®å½•ï¼ˆç”¨äºæ€§èƒ½ä¼˜åŒ–ï¼Œé¿å…æ‰«ææ˜æ˜¾æ— ç”¨çš„ç›®å½•ï¼‰
        exclude_dirs = {
            ".git",
            "__pycache__",
            ".pytest_cache",
            ".coverage",
        }

        # æ‰«ææ ¹ç›®å½•çš„ç›´æ¥æ–‡ä»¶
        for item in workspace_path.iterdir():
            if item.is_file():
                # æ£€æŸ¥æ˜¯å¦è¢« .gitignore æ’é™¤
                relative_path = str(item.relative_to(workspace_path))
                if self.gitignore_parser.is_ignored(relative_path):
                    structure_info["gitignore_excluded_count"] += 1
                    logger.debug(f"æ–‡ä»¶è¢« .gitignore æ’é™¤: {relative_path}")
                    continue

                structure_info["total_files"] += 1

                # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                suffix = item.suffix.lower()
                if suffix:
                    structure_info["file_types"][suffix] = (
                        structure_info["file_types"].get(suffix, 0) + 1
                    )

                # è¯†åˆ«é…ç½®æ–‡ä»¶
                if item.name in [
                    "package.json",
                    "requirements.txt",
                    "pyproject.toml",
                    "Cargo.toml",
                    "go.mod",
                    "conf.yaml",
                    "docker-compose.yml",
                    "Dockerfile",
                    "Makefile",
                ]:
                    structure_info["config_files"].append(item.name)

            elif item.is_dir() and item.name not in exclude_dirs:
                # æ£€æŸ¥ç›®å½•æ˜¯å¦è¢« .gitignore æ’é™¤
                relative_dir_path = str(item.relative_to(workspace_path))
                if self.gitignore_parser.is_ignored(relative_dir_path):
                    logger.debug(f"ç›®å½•è¢« .gitignore æ’é™¤: {relative_dir_path}")
                    continue

                structure_info["total_directories"] += 1
                structure_info["directories"].append(item.name)

                # åˆå§‹åŒ–å½“å‰ç›®å½•ç»“æ„
                current_dir_structure = {"files": [], "subdirectories": {}}

                # æ‰«æç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚å­ç›®å½•çš„æ–‡ä»¶
                try:
                    for subitem in item.iterdir():
                        if subitem.is_file():
                            # æ£€æŸ¥å­æ–‡ä»¶æ˜¯å¦è¢« .gitignore æ’é™¤
                            relative_subfile_path = str(subitem.relative_to(workspace_path))
                            if self.gitignore_parser.is_ignored(relative_subfile_path):
                                structure_info["gitignore_excluded_count"] += 1
                                continue

                            structure_info["total_files"] += 1
                            current_dir_structure["files"].append(subitem.name)
                            suffix = subitem.suffix.lower()
                            if suffix:
                                structure_info["file_types"][suffix] = (
                                    structure_info["file_types"].get(suffix, 0) + 1
                                )
                        elif subitem.is_dir() and subitem.name not in exclude_dirs:
                            # æ£€æŸ¥å­ç›®å½•æ˜¯å¦è¢« .gitignore æ’é™¤
                            relative_subdir_path = str(subitem.relative_to(workspace_path))
                            if self.gitignore_parser.is_ignored(relative_subdir_path):
                                continue
                            # åˆå§‹åŒ–å­ç›®å½•ç»“æ„
                            subdir_structure = {"files": []}

                            # æ‰«æç¬¬äºŒå±‚å­ç›®å½•çš„æ–‡ä»¶
                            try:
                                for subsubitem in subitem.iterdir():
                                    if subsubitem.is_file():
                                        # æ£€æŸ¥æ·±å±‚æ–‡ä»¶æ˜¯å¦è¢« .gitignore æ’é™¤
                                        relative_deep_path = str(subsubitem.relative_to(workspace_path))
                                        if self.gitignore_parser.is_ignored(relative_deep_path):
                                            structure_info["gitignore_excluded_count"] += 1
                                            continue

                                        structure_info["total_files"] += 1
                                        subdir_structure["files"].append(
                                            subsubitem.name
                                        )
                                        suffix = subsubitem.suffix.lower()
                                        if suffix:
                                            structure_info["file_types"][suffix] = (
                                                structure_info["file_types"].get(
                                                    suffix, 0
                                                )
                                                + 1
                                            )
                            except (PermissionError, OSError):
                                # è·³è¿‡æ— æ³•è®¿é—®çš„ç¬¬äºŒå±‚ç›®å½•
                                continue

                            current_dir_structure["subdirectories"][
                                subitem.name
                            ] = subdir_structure
                except (PermissionError, OSError):
                    # è·³è¿‡æ— æ³•è®¿é—®çš„ç›®å½•
                    continue

                # ä¿å­˜å½“å‰ç›®å½•çš„è¯¦ç»†ç»“æ„
                structure_info["directory_structure"][item.name] = current_dir_structure

        # ç¡®å®šä¸»è¦è¯­è¨€
        common_extensions = {
            ".py": "Python",
            ".js": "JavaScript",
            ".ts": "TypeScript",
            ".java": "Java",
            ".go": "Go",
            ".rs": "Rust",
            ".cpp": "C++",
            ".c": "C",
        }

        for ext, count in sorted(
            structure_info["file_types"].items(), key=lambda x: x[1], reverse=True
        ):
            if ext in common_extensions:
                structure_info["main_languages"].append(common_extensions[ext])
            if len(structure_info["main_languages"]) >= 3:
                break

        # æ¨æ–­é¡¹ç›®ç±»å‹
        if "package.json" in structure_info["config_files"]:
            structure_info["project_type"] = "Node.js"
        elif (
            "requirements.txt" in structure_info["config_files"]
            or "pyproject.toml" in structure_info["config_files"]
        ):
            structure_info["project_type"] = "Python"
        elif "Cargo.toml" in structure_info["config_files"]:
            structure_info["project_type"] = "Rust"
        elif "go.mod" in structure_info["config_files"]:
            structure_info["project_type"] = "Go"

        return structure_info

    async def _analyze_environment(
        self, project_structure: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """åˆ†æç¯å¢ƒä¿¡æ¯"""
        import platform
        import sys

        env_info = {
            "platform": platform.system(),
            "python_version": sys.version,
            "working_directory": self.workspace_path,  # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å·¥ä½œç›®å½•
            "workspace_path": self.workspace_path,
            "timestamp": datetime.now().isoformat(),
        }

        # æ£€æŸ¥å¸¸è§çš„ç¯å¢ƒé…ç½®
        workspace_path = Path(self.workspace_path)

        # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
        venv_indicators = [".venv", "venv", "env", "virtualenv"]
        for indicator in venv_indicators:
            if (workspace_path / indicator).exists():
                env_info["virtual_environment"] = indicator
                break
        else:
            env_info["virtual_environment"] = None

        # æ£€æŸ¥åŒ…ç®¡ç†å™¨æ–‡ä»¶
        package_files = {
            "requirements.txt": "pip",
            "pyproject.toml": "pip/poetry/setuptools",
            "package.json": "npm/yarn",
            "Cargo.toml": "cargo",
            "go.mod": "go modules",
        }

        env_info["package_managers"] = []
        for file_name, manager in package_files.items():
            if (workspace_path / file_name).exists():
                env_info["package_managers"].append(manager)

        # æ·»åŠ é¡¹ç›®ç»“æ„ä¿¡æ¯åˆ°ç¯å¢ƒä¿¡æ¯ä¸­
        if project_structure:
            env_info["project_structure"] = {
                "total_files": project_structure.get("total_files", 0),
                "total_directories": project_structure.get("total_directories", 0),
                "directories": project_structure.get("directories", []),
                "directory_structure": project_structure.get("directory_structure", {}),
                "main_languages": project_structure.get("main_languages", []),
                "project_type": project_structure.get("project_type", "Unknown"),
                "config_files": project_structure.get("config_files", []),
                "file_types": project_structure.get("file_types", {}),
            }

        return env_info

    def _generate_text_summary(
        self, project_structure: Dict[str, Any], environment_info: Dict[str, Any]
    ) -> str:
        """Generate environment analysis summary in English Markdown format"""
        try:
            # Extract key information
            total_files = project_structure.get("total_files", 0)
            total_dirs = project_structure.get("total_directories", 0)
            file_types = project_structure.get("file_types", {})
            config_files = project_structure.get("config_files", [])
            directories = project_structure.get("directories", [])
            main_languages = project_structure.get("main_languages", [])
            project_type = project_structure.get("project_type", "Unknown")

            platform = environment_info.get("platform", "Unknown")
            python_version = environment_info.get("python_version", "Unknown")
            working_dir = environment_info.get("working_directory", "Unknown")
            venv = environment_info.get("virtual_environment")
            package_managers = environment_info.get("package_managers", [])
            timestamp = environment_info.get("timestamp", "Unknown")

            # Build Markdown summary
            md_lines = []

            # === Project Overview ===
            md_lines.append("# Project Environment Analysis Report")
            md_lines.append("")
            md_lines.append(f"**Analysis Time:** {timestamp}")
            md_lines.append(f"**Working Directory:** `{working_dir}`")
            md_lines.append("")

            # === Project Structure ===
            md_lines.append("## ğŸ“ Project Structure")
            md_lines.append("")
            md_lines.append(f"- **Project Type:** {project_type}")
            md_lines.append(f"- **Total Files:** {total_files}")
            md_lines.append(f"- **Total Directories:** {total_dirs}")

            if main_languages:
                md_lines.append(f"- **Primary Languages:** {', '.join(main_languages)}")

            # File type distribution
            if file_types:
                md_lines.append("")
                md_lines.append("### File Type Distribution")
                md_lines.append("")
                md_lines.append("| Extension | File Count |")
                md_lines.append("|-----------|------------|")
                for ext, count in sorted(
                    file_types.items(), key=lambda x: x[1], reverse=True
                )[:10]:
                    md_lines.append(f"| `{ext}` | {count} |")

            # Configuration files
            if config_files:
                md_lines.append("")
                md_lines.append("### Configuration Files")
                md_lines.append("")
                for config_file in config_files:
                    md_lines.append(f"- `{config_file}`")

            # Main directories
            if directories:
                md_lines.append("")
                md_lines.append("### Main Directories")
                md_lines.append("")
                for directory in directories[:10]:
                    md_lines.append(f"- `{directory}/`")
                if len(directories) > 10:
                    md_lines.append(
                        f"- *...and {len(directories)-10} more directories*"
                    )

            # Detailed directory structure
            directory_structure = project_structure.get("directory_structure", {})
            if directory_structure:
                md_lines.append("")
                md_lines.append("### Directory Structure Details")
                md_lines.append("")

                # éå†ä¸»è¦ç›®å½•
                for dir_name, dir_info in list(directory_structure.items())[
                    :5
                ]:  # åªæ˜¾ç¤ºå‰5ä¸ªç›®å½•
                    md_lines.append(f"#### `{dir_name}/`")

                    # æ˜¾ç¤ºç›´æ¥æ–‡ä»¶
                    files = dir_info.get("files", [])
                    if files:
                        md_lines.append(
                            f"- **Files ({len(files)})**: {', '.join([f'`{f}`' for f in files[:8]])}"
                        )
                        if len(files) > 8:
                            md_lines.append(f"  *(+{len(files)-8} more files)*")

                    # æ˜¾ç¤ºå­ç›®å½•
                    subdirs = dir_info.get("subdirectories", {})
                    if subdirs:
                        md_lines.append(f"- **Subdirectories ({len(subdirs)})**:")
                        for subdir_name, subdir_info in list(subdirs.items())[
                            :3
                        ]:  # åªæ˜¾ç¤ºå‰3ä¸ªå­ç›®å½•
                            subdir_files = subdir_info.get("files", [])
                            if subdir_files:
                                md_lines.append(
                                    f"  - `{subdir_name}/` ({len(subdir_files)} files)"
                                )
                            else:
                                md_lines.append(f"  - `{subdir_name}/`")
                        if len(subdirs) > 3:
                            md_lines.append(
                                f"  *(+{len(subdirs)-3} more subdirectories)*"
                            )

                    md_lines.append("")

                if len(directory_structure) > 5:
                    md_lines.append(
                        f"*...and {len(directory_structure)-5} more directories*"
                    )
                    md_lines.append("")

            md_lines.append("")

            # === Runtime Environment ===
            md_lines.append("## ğŸ”§ Runtime Environment")
            md_lines.append("")
            md_lines.append(f"- **Operating System:** {platform}")
            md_lines.append(
                f"- **Python Version:** {python_version.split()[0] if python_version != 'Unknown' else 'Unknown'}"
            )

            # Virtual environment
            if venv:
                md_lines.append(f"- **Virtual Environment:** `{venv}`")
            else:
                md_lines.append("- **Virtual Environment:** Not detected")

            # Package managers
            if package_managers:
                md_lines.append(
                    f"- **Package Managers:** {', '.join(package_managers)}"
                )
            else:
                md_lines.append("- **Package Managers:** Not detected")

            # === Summary ===
            md_lines.append("")
            md_lines.append("## ğŸ“‹ Environment Summary")
            md_lines.append("")

            if project_type != "Unknown":
                md_lines.append(f"- **{project_type}** project")
            if main_languages:
                md_lines.append(f"- **{main_languages[0]}** development")
            if total_files > 0:
                md_lines.append(
                    f"- **{total_files}** files, **{total_dirs}** directories"
                )
            if venv:
                md_lines.append(f"- **{venv}** virtual environment")

            return "\n".join(md_lines)

        except Exception as e:
            logger.error(f"Failed to generate text summary: {e}")
            return f"# Error\n\nUnable to generate text summary: {str(e)}"

    def save_analysis_result(
        self,
        project_structure: Dict[str, Any],
        environment_info: Dict[str, Any],
        indexed_files_count: int,
        rag_status: str,
    ) -> WorkspaceAnalysis:
        """ä¿å­˜åˆ†æç»“æœ"""

        # ç”Ÿæˆåˆ†ææ‘˜è¦
        main_languages = project_structure.get("main_languages", [])
        project_type = project_structure.get("project_type", "unknown")
        total_files = project_structure.get("total_files", 0)

        summary = (
            f"{project_type}é¡¹ç›®ï¼Œä¸»è¦è¯­è¨€ï¼š{', '.join(main_languages[:2])}ï¼Œ"
            f"å…±{total_files}ä¸ªæ–‡ä»¶ï¼Œç´¢å¼•{indexed_files_count}ä¸ªï¼ŒRAGçŠ¶æ€ï¼š{rag_status}"
        )

        analysis = WorkspaceAnalysis(
            workspace_hash=self.state_manager.workspace_hash,
            analysis_time=datetime.now(),
            project_structure=project_structure,
            environment_info=environment_info,
            indexed_files_count=indexed_files_count,
            rag_status=rag_status,
            analysis_summary=summary,
        )

        self.state_manager.save_analysis(analysis)
        logger.info(f"åˆ†æç»“æœå·²ä¿å­˜: {summary}")

        return analysis

    def get_workspace_context_for_retrieval(self) -> Optional[Dict[str, Any]]:
        """è·å–å¯ç”¨äºæ£€ç´¢çš„å·¥ä½œåŒºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            summary = self.state_manager.get_workspace_summary()
            analyses = self.state_manager.get_analysis_history()

            if not analyses:
                logger.info("æ— å¯ç”¨çš„å·¥ä½œåŒºåˆ†æå†å²")
                return None

            latest_analysis = analyses[-1]

            context = {
                "workspace_summary": summary,
                "latest_analysis": {
                    "project_structure": latest_analysis.project_structure,
                    "environment_info": latest_analysis.environment_info,
                    "analysis_summary": latest_analysis.analysis_summary,
                    "rag_status": latest_analysis.rag_status,
                    "indexed_files_count": latest_analysis.indexed_files_count,
                },
                "is_context_available": True,
                "context_age_days": (
                    (datetime.now() - latest_analysis.analysis_time).days
                ),
            }

            logger.info(f"å·¥ä½œåŒºä¸Šä¸‹æ–‡å¯ç”¨ï¼Œåˆ†ææ—¶é—´ï¼š{latest_analysis.analysis_time}")
            return context

        except Exception as e:
            logger.error(f"è·å–å·¥ä½œåŒºä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return None
